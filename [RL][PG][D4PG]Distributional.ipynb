{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ATg2s26AhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "51e73a92-9347-45ef-905b-3d674c4ad499"
      },
      "source": [
        "!apt-get install swig\n",
        "!pip3 install box2d box2d-kengz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "swig is already the newest version (3.0.12-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Requirement already satisfied: box2d in /usr/local/lib/python3.6/dist-packages (2.3.2)\n",
            "Requirement already satisfied: box2d-kengz in /usr/local/lib/python3.6/dist-packages (2.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aE6-lCM6oqv3",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "from collections import namedtuple\n",
        "\n",
        "version = \"1.0.0\"\n",
        "\n",
        "StepInfo = namedtuple(\"StepInfo\", (\"obs\", \"act_v\", \"noise_v\", \"act\", \"last_obs\", \"rew\", \"done\", \"etc\", \"n\"))\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, env, actor, noise = None, max_step = None, device = None):\n",
        "        self.env = env\n",
        "        if max_step is not None:\n",
        "            self.env._max_episode_steps = max_step\n",
        "        if device is None:\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")            \n",
        "        self.actor = actor\n",
        "        self.noise = noise\n",
        "        self.device = device\n",
        "        \n",
        "        self.wait = -1\n",
        "        self.interval = -1\n",
        "        self.frame = None\n",
        "        \n",
        "        self.step_set = False\n",
        "        self.n_step = 1\n",
        "        self.gamma = 0.99\n",
        "        self.scale_factor = 1\n",
        "        self.bias=0\n",
        "        \n",
        "    def prepare(self, step_unroll, gamma, scale=1, bias=0):\n",
        "        self.step_set = True\n",
        "        self.n_step = step_unroll\n",
        "        self.gamma= gamma\n",
        "        self.scale_factor = scale\n",
        "        self.bias=bias\n",
        "        \n",
        "    def set_renderer(self, rend_wait=0, rend_interval=1, frame = None):\n",
        "        self.wait = rend_wait\n",
        "        self.interval = rend_interval\n",
        "        self.frame = frame\n",
        "        \n",
        "    def reset(self):\n",
        "        self.env.close()\n",
        "        self.env.reset()\n",
        "        \n",
        "    def render(self, epoch):\n",
        "        if self.wait >= 0 and epoch < self.wait:\n",
        "            return\n",
        "        if self.interval >= 0 and epoch % self.interval == 0:\n",
        "            rend = self.env.render(\"rgb_array\")\n",
        "            if self.frame is not None:\n",
        "                self.frame.append(self.env.render(\"rgb_array\"))\n",
        "        \n",
        "    def episode(self, epoch):\n",
        "        assert self.step_set\n",
        "        buffer = []\n",
        "        self.obs = self.env.reset()\n",
        "        self.render(epoch)\n",
        "\n",
        "        total_rew = 0\n",
        "        total_rew_scaled = 0\n",
        "        count = 0\n",
        "        while True:\n",
        "            with torch.no_grad():\n",
        "                act_v = self.actor(torch.FloatTensor([self.obs]).to(self.device)).cpu().squeeze(0).numpy()\n",
        "                if self.noise is not None:\n",
        "                    noise_v = act_v + self.noise.get_noise()\n",
        "                else:\n",
        "                    noise_v = act_v\n",
        "                if self.env.action_space.shape:\n",
        "                    noise_v = noise_v.clip(self.env.action_space.low, self.env.action_space.high)\n",
        "                act = self.actor.get_action(noise_v)\n",
        "\n",
        "            next_obs, rew, done, etc = self.env.step(act)\n",
        "            obs = self.obs\n",
        "            self.obs = next_obs\n",
        "            count += 1\n",
        "\n",
        "            total_rew_scaled += rew\n",
        "            rew += self.bias\n",
        "            rew /= self.scale_factor\n",
        "            total_rew += rew\n",
        "\n",
        "            self.render(epoch)\n",
        "\n",
        "            buffer.append(StepInfo(obs, act_v, noise_v, act, next_obs, rew, done, etc, -1))\n",
        "            if done:\n",
        "                break\n",
        "                \n",
        "            if len(buffer) < self.n_step:\n",
        "                continue\n",
        "                \n",
        "            yield self.unroll_step(buffer)\n",
        "            buffer.pop(0)\n",
        "            \n",
        "        while len(buffer):\n",
        "            yield self.unroll_step(buffer)\n",
        "            buffer.pop(0)\n",
        "        print(\"ep#%4d\"%epoch, \"count : %4d, scaled_rew : %03.5f, total_rew : %03.5f\"%(count, total_rew, total_rew_scaled))\n",
        "        return\n",
        "\n",
        "    def unroll_step(self, buffer):\n",
        "        assert len(buffer)\n",
        "        \n",
        "        rews = list(map(lambda b:b.rew, buffer))\n",
        "        rews.reverse()\n",
        "        rew_sum = 0\n",
        "\n",
        "        for r in rews:\n",
        "            rew_sum*=self.gamma\n",
        "            rew_sum+=r\n",
        "            \n",
        "        done = buffer[-1].done if len(buffer) == self.n_step else True\n",
        "        return StepInfo(buffer[0].obs, buffer[0].act_v, buffer[0].noise_v, buffer[0].act, buffer[-1].last_obs, rew_sum, done, buffer[0].etc, len(buffer))\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class NoiseMaker():\n",
        "    def __init__(self, action_size, n_type = None, param = None, decay = True):\n",
        "        self.action_size = action_size\n",
        "        self.state = np.zeros(action_size, dtype=np.float32)\n",
        "        self.count = 0\n",
        "        self.decay = decay\n",
        "        if n_type is None:\n",
        "            n_type = \"normal\"\n",
        "        self.type = n_type\n",
        "        \n",
        "        if param is None:\n",
        "            self.param = {\n",
        "                \"start\": 0.9,\n",
        "                \"end\":0.02,\n",
        "                \"decay\": 2000\n",
        "            }\n",
        "            if n_type ==\"ou\":\n",
        "                self.param[\"ou_mu\"] = 0.0\n",
        "                self.param[\"ou_th\"] = 0.15\n",
        "                self.param[\"ou_sig\"] = 0.2\n",
        "        else:\n",
        "            self.param = param\n",
        "            \n",
        "    def get_noise(self):\n",
        "        eps = self.param[\"end\"] + (self.param[\"start\"] - self.param[\"end\"]) * math.exp(-1*self.count/ self.param[\"decay\"])\n",
        "        \n",
        "        noise = np.random.normal(size=self.action_size)\n",
        "        if self.type == \"ou\":\n",
        "            self.state += self.param[\"ou_th\"] * (self.param[\"ou_mu\"] - self.state) + self.param[\"ou_sig\"] * noise\n",
        "            noise = self.state\n",
        "        if not self.decay:\n",
        "            eps = 1\n",
        "        self.count += 1\n",
        "            \n",
        "        return noise * eps\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class Replay:\n",
        "    def __init__(self, size, prio = False, alph = 0.6, beta = 0.4):\n",
        "        self.memory = collections.deque(maxlen = size)\n",
        "        self.size = size\n",
        "        self.priorities = collections.deque(maxlen = size)\n",
        "        self.prio = prio\n",
        "        self.alph = alph if prio else 0\n",
        "        self.beta = beta if prio else 0\n",
        "        self.count = 0\n",
        "        \n",
        "    def push(self, data):\n",
        "        self.memory.append(data)\n",
        "        self.count += 1\n",
        "        if self.prio:\n",
        "            max_prio = np.array(self.priorities).max() if len(self.priorities) else 1.\n",
        "            self.priorities.append(max_prio)\n",
        "        \n",
        "    def prepare(self, env):\n",
        "        pass\n",
        "        \n",
        "    def sample(self, size):\n",
        "        if self.prio:\n",
        "            probs = np.array(self.priorities, dtype=np.float32)\n",
        "            min_prio = np.array(self.priorities).min()\n",
        "            if min_prio < 1:\n",
        "                probs /= min_prio\n",
        "            probs = probs ** self.alph\n",
        "            probs /= probs.sum()\n",
        "        else:\n",
        "            probs = np.ones(len(self),) / len(self)\n",
        "        \n",
        "        indices = np.random.choice(len(self), size, p=probs)\n",
        "        sample = [self.memory[idx] for idx in indices]\n",
        "        \n",
        "        beta = 1. + (self.beta - 1.) * math.exp(-1 * self.count / self.size)\n",
        "        weights = (len(self) * probs[indices]) ** (-beta)\n",
        "        weights /= weights.sum()\n",
        "        \n",
        "        return sample, indices, weights\n",
        "        \n",
        "    def update_priorities(self, indices, prios):\n",
        "        if not self.prio:\n",
        "            return\n",
        "        prios += 1e-8\n",
        "        for idx, prio in zip(indices,prios):\n",
        "            self.priorities[idx] = prio\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vYxEy8Q6oqwJ",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "import math\n",
        "\n",
        "class NoiseLinear(nn.Linear):\n",
        "    def __init__(self, in_, out_, val = 0.017, bias = True):\n",
        "        super(NoiseLinear, self).__init__(in_,out_,bias)\n",
        "        self.sigma_weight = nn.Parameter(torch.full((out_, in_), val))\n",
        "        self.register_buffer(\"eps_weight\", torch.zeros(out_, in_))\n",
        "        if bias:\n",
        "            self.sigma_bias = nn.Parameter(torch.full((out_,), val))\n",
        "            self.register_buffer(\"eps_bias\", torch.zeros(out_))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = math.sqrt(1 / self.in_features)\n",
        "        self.weight.data.uniform_(-std, std)\n",
        "        self.bias.data.uniform_(-std, std)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        self.eps_weight.normal_()\n",
        "        bias = self.bias\n",
        "        if bias is not None:\n",
        "            self.eps_bias.normal_()\n",
        "            bias = bias + self.sigma_bias * self.eps_bias.data\n",
        "        return F.linear(x, self.weight + self.sigma_weight * self.eps_weight, bias)\n",
        "\n",
        "class targetNet(nn.Module):\n",
        "    def __init__(self, off_net):\n",
        "        super(targetNet, self).__init__()\n",
        "        self.net = copy.deepcopy(off_net)\n",
        "        self.off_net = off_net\n",
        "        \n",
        "    def alpha_update(self, alpha = 0.05):\n",
        "        for off, tgt in zip(self.off_net.parameters(), self.net.parameters()):\n",
        "            tgt.data.copy_(off.data*alpha + tgt.data*(1-alpha))\n",
        "    \n",
        "    def copy_off_net(self):\n",
        "        self.net.load_state_dict(self.off_net.state_dict())\n",
        "    \n",
        "    def forward(self, *x):\n",
        "        return self.net(*x)\n",
        "        \n",
        "\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, in_, act_n, action_provider, hidden=512):\n",
        "        super(Actor, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, int(hidden/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(hidden/2), act_n),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.action_provider = action_provider\n",
        "        \n",
        "    def get_action(self, act_v):\n",
        "        return self.action_provider(act_v)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DistCritic(nn.Module):\n",
        "    def __init__(self, in_, act_v, atom=51, hidden=512):\n",
        "        super(DistCritic, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_, hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.net_out = nn.Sequential(\n",
        "            nn.Linear(hidden + act_n, int(hidden/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(hidden/2), atom)\n",
        "        )\n",
        "    \n",
        "    def forward(self, obs, act):\n",
        "        return self.net_out(torch.cat([self.net(obs), act], dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJrRlHDroqwm",
        "colab": {}
      },
      "source": [
        "V_MAX = 10\n",
        "V_MIN = -5\n",
        "ATOMS = 51\n",
        "V_DIST = (V_MAX-V_MIN)/(ATOMS-1)\n",
        "\n",
        "def transform_dist(dist, rew, gamma, unroll_n, done):\n",
        "    support_start = V_MIN\n",
        "    \n",
        "    dist = dist.cpu().detach().numpy()\n",
        "    ret = np.zeros_like(dist)\n",
        "    rew = rew.cpu().numpy()\n",
        "    unroll_n = unroll_n.cpu().numpy()\n",
        "    done = done.cpu().numpy()\n",
        "    for atom in range(ATOMS):\n",
        "        support = support_start + atom * V_DIST\n",
        "        next_support = rew + (gamma**unroll_n) * support\n",
        "        next_support[next_support > V_MAX] = V_MAX\n",
        "        next_support[next_support < V_MIN] = V_MIN\n",
        "\n",
        "        indices = ((next_support - V_MIN) / V_DIST).squeeze()\n",
        "        l = np.floor(indices).astype(np.int64)\n",
        "        r = np.ceil(indices).astype(np.int64)\n",
        "\n",
        "        eq = l==r\n",
        "        ret[eq, l[eq]] += dist[eq, atom]\n",
        "        neq = l!=r\n",
        "        ret[neq, l[neq]] += dist[neq, atom] * (r - indices)[neq]\n",
        "        ret[neq, r[neq]] += dist[neq, atom] * (indices - l)[neq]\n",
        "\n",
        "        if done.any():\n",
        "            ret[done] = 0.0\n",
        "            next_support = rew[done]\n",
        "            next_support[next_support > V_MAX] = V_MAX\n",
        "            next_support[next_support < V_MIN] = V_MIN\n",
        "\n",
        "            indices = ((next_support - V_MIN) / V_DIST).squeeze()\n",
        "            l = np.floor(indices).astype(np.int64)\n",
        "            r = np.ceil(indices).astype(np.int64)\n",
        "\n",
        "            eq = l==r\n",
        "            eq_done = done.copy()\n",
        "            eq_done[done] = eq\n",
        "            if eq_done.any():\n",
        "                ret[eq_done, l[eq]] = 1.0\n",
        "\n",
        "            neq = l!=r\n",
        "            neq_done = done.copy()\n",
        "            neq_done[done] = neq\n",
        "            if neq_done.any():\n",
        "                ret[neq_done, l[neq]] = (r - indices)[neq]\n",
        "                ret[neq_done, r[neq]] = (indices - l)[neq]\n",
        "            \n",
        "    return torch.FloatTensor(ret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DxDEeOCfoqwd",
        "outputId": "dd6e5425-5e73-41ce-a4a8-5a1b872b19dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "ACT_LR = 0.001\n",
        "CRT_LR = 0.001\n",
        "GAMMA = 0.99\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")     \n",
        "\n",
        "env = gym.make(\"BipedalWalker-v3\")\n",
        "act_n = env.action_space.shape[0]\n",
        "obs_n = env.observation_space.shape[0]\n",
        "\n",
        "actor = Actor(obs_n, act_n, lambda x:x).to(device)\n",
        "actor_tgt = targetNet(actor)\n",
        "actor_optim = optim.Adam(actor.parameters(), ACT_LR)\n",
        "\n",
        "critic = DistCritic(obs_n, act_n, ATOMS).to(device)\n",
        "critic_tgt = targetNet(critic)\n",
        "critic_optim = optim.Adam(critic.parameters(), CRT_LR)\n",
        "\n",
        "ST_SIZE = 50000\n",
        "ST_INIT = 10000\n",
        "ST_DECAY = 5000\n",
        "BATCH = 512\n",
        "\n",
        "storage = Replay(ST_SIZE, True)\n",
        "noise = NoiseMaker(act_n, \"ou\", decay=True)\n",
        "noise.param[\"ou_sig\"] = 0.6\n",
        "noise.param[\"decay\"] = ST_SIZE\n",
        "\n",
        "agent = Agent(env, actor, noise, device=device)\n",
        "agent.prepare(3, GAMMA, 30)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vvt1_9i0oqxQ",
        "outputId": "aa2b7252-2290-40e4-ebb3-1f9929de0801",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "EPOCH = 2000\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    for i, step in enumerate(agent.episode(epoch)):\n",
        "        storage.push(step)\n",
        "        if len(storage) < ST_INIT:\n",
        "            continue\n",
        "            \n",
        "        sample, indices, weights = storage.sample(BATCH)\n",
        "        weights_ = torch.FloatTensor(weights).to(device)\n",
        "        obs, act_v, noise_v, act, next_obs, rew, done, etc, unroll_n = list(zip(*sample))\n",
        "        \n",
        "        obs_ = torch.FloatTensor(obs).to(device)\n",
        "        act_v_ = torch.FloatTensor(act_v).to(device)\n",
        "        noise_v_ = torch.FloatTensor(noise_v).to(device)\n",
        "        act_ = torch.LongTensor(act).unsqueeze(1).to(device)\n",
        "        next_obs_ = torch.FloatTensor(next_obs).to(device)\n",
        "        rew_ = torch.FloatTensor(rew).unsqueeze(1).to(device)\n",
        "        done_ = torch.BoolTensor(done).to(device)\n",
        "        unroll_n_ = torch.FloatTensor(unroll_n).unsqueeze(1).to(device)\n",
        "\n",
        "        #Critic update\n",
        "        critic_optim.zero_grad()\n",
        "        q_pred = critic(obs_, noise_v_)\n",
        "        \n",
        "        q_next_prob = critic_tgt(next_obs_, actor_tgt(next_obs_))\n",
        "        q_next = F.softmax(q_next_prob, dim=1)\n",
        "        q_target = transform_dist(q_next, rew_, GAMMA, unroll_n_, done_).to(device)\n",
        "\n",
        "        q_entropy = -F.log_softmax(q_pred, dim=1) * q_target\n",
        "        q_entropy_sum = q_entropy.sum(dim=1)\n",
        "        q_loss = (weights_ * q_entropy_sum).sum()\n",
        "        q_loss.backward()\n",
        "        critic_optim.step()\n",
        "\n",
        "        storage.update_priorities(indices, q_entropy_sum.cpu().detach().numpy())\n",
        "\n",
        "        #Actor update\n",
        "        actor_optim.zero_grad()\n",
        "        \n",
        "        #history decaying\n",
        "        st_decay = torch.exp_(-torch.FloatTensor(len(storage)-indices)/ST_DECAY).unsqueeze(1).to(device)\n",
        "        act_avg = actor(obs_) * (1-st_decay) + act_v_ * st_decay\n",
        "        q_dist = critic(obs_,act_avg)\n",
        "        \n",
        "        q_v = -F.softmax(q_dist,dim=1) * torch.arange(V_MIN, V_MAX + V_DIST - 1e-8, V_DIST).to(device)\n",
        "        q_v = q_v.mean(dim=1)\n",
        "\n",
        "        actor_loss = q_v.mean()\n",
        "        actor_loss.backward()\n",
        "        actor_optim.step()\n",
        "\n",
        "        #target update\n",
        "        critic_tgt.alpha_update()\n",
        "        actor_tgt.alpha_update()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ep#   0 count :  122, scaled_rew : -3.95219, total_rew : -118.56573\n",
            "ep#   1 count :   39, scaled_rew : -3.82891, total_rew : -114.86728\n",
            "ep#   2 count :   65, scaled_rew : -3.46146, total_rew : -103.84365\n",
            "ep#   3 count :  132, scaled_rew : -3.56875, total_rew : -107.06239\n",
            "ep#   4 count :   79, scaled_rew : -3.77794, total_rew : -113.33821\n",
            "ep#   5 count :  107, scaled_rew : -4.21066, total_rew : -126.31990\n",
            "ep#   6 count :  110, scaled_rew : -3.33480, total_rew : -100.04394\n",
            "ep#   7 count :   43, scaled_rew : -3.76773, total_rew : -113.03189\n",
            "ep#   8 count :   96, scaled_rew : -3.85814, total_rew : -115.74435\n",
            "ep#   9 count :   77, scaled_rew : -3.33190, total_rew : -99.95697\n",
            "ep#  10 count :  122, scaled_rew : -3.66036, total_rew : -109.81073\n",
            "ep#  11 count :   56, scaled_rew : -4.12780, total_rew : -123.83396\n",
            "ep#  12 count :   55, scaled_rew : -3.86181, total_rew : -115.85424\n",
            "ep#  13 count :   90, scaled_rew : -3.63319, total_rew : -108.99569\n",
            "ep#  14 count :  103, scaled_rew : -3.62144, total_rew : -108.64309\n",
            "ep#  15 count :   47, scaled_rew : -3.63362, total_rew : -109.00859\n",
            "ep#  16 count :   76, scaled_rew : -3.91542, total_rew : -117.46257\n",
            "ep#  17 count :   64, scaled_rew : -3.87934, total_rew : -116.38007\n",
            "ep#  18 count :  147, scaled_rew : -3.97037, total_rew : -119.11103\n",
            "ep#  19 count :  278, scaled_rew : -3.76042, total_rew : -112.81263\n",
            "ep#  20 count :   43, scaled_rew : -3.85975, total_rew : -115.79243\n",
            "ep#  21 count :  308, scaled_rew : -4.09305, total_rew : -122.79150\n",
            "ep#  22 count :  171, scaled_rew : -4.21905, total_rew : -126.57164\n",
            "ep#  23 count :   84, scaled_rew : -3.91564, total_rew : -117.46919\n",
            "ep#  24 count :   53, scaled_rew : -3.40212, total_rew : -102.06367\n",
            "ep#  25 count :   69, scaled_rew : -3.92325, total_rew : -117.69760\n",
            "ep#  26 count :  109, scaled_rew : -3.25959, total_rew : -97.78781\n",
            "ep#  27 count :  262, scaled_rew : -4.69769, total_rew : -140.93069\n",
            "ep#  28 count :   39, scaled_rew : -3.69663, total_rew : -110.89885\n",
            "ep#  29 count :   65, scaled_rew : -3.24577, total_rew : -97.37304\n",
            "ep#  30 count :   44, scaled_rew : -3.63865, total_rew : -109.15940\n",
            "ep#  31 count :  112, scaled_rew : -3.30712, total_rew : -99.21350\n",
            "ep#  32 count :   73, scaled_rew : -3.49283, total_rew : -104.78486\n",
            "ep#  33 count :   79, scaled_rew : -4.00210, total_rew : -120.06306\n",
            "ep#  34 count :   62, scaled_rew : -3.35935, total_rew : -100.78050\n",
            "ep#  35 count :   59, scaled_rew : -3.77679, total_rew : -113.30384\n",
            "ep#  36 count :  122, scaled_rew : -3.43615, total_rew : -103.08437\n",
            "ep#  37 count :   48, scaled_rew : -3.38804, total_rew : -101.64106\n",
            "ep#  38 count :   45, scaled_rew : -3.56736, total_rew : -107.02095\n",
            "ep#  39 count :   52, scaled_rew : -3.94100, total_rew : -118.23013\n",
            "ep#  40 count :   72, scaled_rew : -3.45013, total_rew : -103.50402\n",
            "ep#  41 count :  173, scaled_rew : -4.26238, total_rew : -127.87152\n",
            "ep#  42 count :   75, scaled_rew : -4.23005, total_rew : -126.90155\n",
            "ep#  43 count :  255, scaled_rew : -4.52817, total_rew : -135.84516\n",
            "ep#  44 count :   50, scaled_rew : -3.72388, total_rew : -111.71647\n",
            "ep#  45 count :  254, scaled_rew : -3.98814, total_rew : -119.64435\n",
            "ep#  46 count :  351, scaled_rew : -3.74914, total_rew : -112.47417\n",
            "ep#  47 count :   62, scaled_rew : -3.44267, total_rew : -103.28019\n",
            "ep#  48 count :   53, scaled_rew : -3.91803, total_rew : -117.54091\n",
            "ep#  49 count :   35, scaled_rew : -3.56066, total_rew : -106.81990\n",
            "ep#  50 count : 1600, scaled_rew : -1.22540, total_rew : -36.76188\n",
            "ep#  51 count :   81, scaled_rew : -3.37930, total_rew : -101.37890\n",
            "ep#  52 count : 1600, scaled_rew : -1.18709, total_rew : -35.61280\n",
            "ep#  53 count :  146, scaled_rew : -4.13041, total_rew : -123.91239\n",
            "ep#  54 count :   99, scaled_rew : -3.17720, total_rew : -95.31586\n",
            "ep#  55 count :  126, scaled_rew : -3.17633, total_rew : -95.28985\n",
            "ep#  56 count :   76, scaled_rew : -3.92657, total_rew : -117.79702\n",
            "ep#  57 count : 1219, scaled_rew : -4.08353, total_rew : -122.50588\n",
            "ep#  58 count :   82, scaled_rew : -3.75383, total_rew : -112.61499\n",
            "ep#  59 count :   38, scaled_rew : -3.94063, total_rew : -118.21893\n",
            "ep#  60 count :   80, scaled_rew : -3.75039, total_rew : -112.51158\n",
            "ep#  61 count :  166, scaled_rew : -4.60966, total_rew : -138.28994\n",
            "ep#  62 count :  106, scaled_rew : -3.87319, total_rew : -116.19579\n",
            "ep#  63 count :   42, scaled_rew : -4.11295, total_rew : -123.38862\n",
            "ep#  64 count :  182, scaled_rew : -4.08683, total_rew : -122.60487\n",
            "ep#  65 count :   46, scaled_rew : -3.98000, total_rew : -119.40001\n",
            "ep#  66 count :   46, scaled_rew : -3.97355, total_rew : -119.20645\n",
            "ep#  67 count :  106, scaled_rew : -3.86484, total_rew : -115.94525\n",
            "ep#  68 count :  173, scaled_rew : -4.05925, total_rew : -121.77739\n",
            "ep#  69 count : 1600, scaled_rew : -5.58144, total_rew : -167.44307\n",
            "ep#  70 count : 1600, scaled_rew : -5.26600, total_rew : -157.98000\n",
            "ep#  71 count : 1183, scaled_rew : -6.56252, total_rew : -196.87548\n",
            "ep#  72 count :  164, scaled_rew : -3.35946, total_rew : -100.78383\n",
            "ep#  73 count : 1600, scaled_rew : -2.02906, total_rew : -60.87191\n",
            "ep#  74 count : 1600, scaled_rew : -3.94454, total_rew : -118.33616\n",
            "ep#  75 count :   89, scaled_rew : -3.38640, total_rew : -101.59193\n",
            "ep#  76 count :   71, scaled_rew : -3.52721, total_rew : -105.81632\n",
            "ep#  77 count : 1600, scaled_rew : -3.51020, total_rew : -105.30596\n",
            "ep#  78 count :  103, scaled_rew : -4.01791, total_rew : -120.53733\n",
            "ep#  79 count :  216, scaled_rew : -3.40902, total_rew : -102.27052\n",
            "ep#  80 count : 1600, scaled_rew : 0.92044, total_rew : 27.61323\n",
            "ep#  81 count : 1343, scaled_rew : -6.52015, total_rew : -195.60459\n",
            "ep#  82 count :   87, scaled_rew : -3.98198, total_rew : -119.45950\n",
            "ep#  83 count :  637, scaled_rew : -3.67564, total_rew : -110.26932\n",
            "ep#  84 count :  335, scaled_rew : -5.14137, total_rew : -154.24100\n",
            "ep#  85 count : 1281, scaled_rew : -7.59093, total_rew : -227.72801\n",
            "ep#  86 count :   51, scaled_rew : -3.88813, total_rew : -116.64377\n",
            "ep#  87 count : 1588, scaled_rew : -6.16590, total_rew : -184.97699\n",
            "ep#  88 count : 1509, scaled_rew : -2.76953, total_rew : -83.08581\n",
            "ep#  89 count :  937, scaled_rew : -1.86912, total_rew : -56.07372\n",
            "ep#  90 count : 1600, scaled_rew : 4.36272, total_rew : 130.88154\n",
            "ep#  91 count : 1600, scaled_rew : 5.48283, total_rew : 164.48493\n",
            "ep#  92 count :  128, scaled_rew : -3.89634, total_rew : -116.89010\n",
            "ep#  93 count :  333, scaled_rew : -2.89268, total_rew : -86.78036\n",
            "ep#  94 count :  392, scaled_rew : -4.49803, total_rew : -134.94080\n",
            "ep#  95 count :  259, scaled_rew : -3.41000, total_rew : -102.30010\n",
            "ep#  96 count : 1600, scaled_rew : 6.51791, total_rew : 195.53720\n",
            "ep#  97 count :  383, scaled_rew : -2.47044, total_rew : -74.11318\n",
            "ep#  98 count : 1102, scaled_rew : -0.53451, total_rew : -16.03541\n",
            "ep#  99 count :  739, scaled_rew : -0.02488, total_rew : -0.74639\n",
            "ep# 100 count : 1565, scaled_rew : 7.25210, total_rew : 217.56302\n",
            "ep# 101 count : 1600, scaled_rew : 6.55132, total_rew : 196.53961\n",
            "ep# 102 count :  721, scaled_rew : -3.19144, total_rew : -95.74317\n",
            "ep# 103 count : 1467, scaled_rew : 7.68579, total_rew : 230.57357\n",
            "ep# 104 count :  177, scaled_rew : -4.50224, total_rew : -135.06715\n",
            "ep# 105 count :  616, scaled_rew : -2.11036, total_rew : -63.31069\n",
            "ep# 106 count :  571, scaled_rew : -1.09739, total_rew : -32.92171\n",
            "ep# 107 count :  478, scaled_rew : -1.74022, total_rew : -52.20661\n",
            "ep# 108 count :  122, scaled_rew : -3.90344, total_rew : -117.10319\n",
            "ep# 109 count :   40, scaled_rew : -3.68547, total_rew : -110.56407\n",
            "ep# 110 count :   44, scaled_rew : -3.95032, total_rew : -118.50960\n",
            "ep# 111 count :   57, scaled_rew : -3.96752, total_rew : -119.02549\n",
            "ep# 112 count :   40, scaled_rew : -3.83972, total_rew : -115.19149\n",
            "ep# 113 count :  528, scaled_rew : -4.49299, total_rew : -134.78964\n",
            "ep# 114 count : 1125, scaled_rew : -5.28145, total_rew : -158.44346\n",
            "ep# 115 count : 1600, scaled_rew : 1.58068, total_rew : 47.42025\n",
            "ep# 116 count :  321, scaled_rew : -2.70155, total_rew : -81.04661\n",
            "ep# 117 count : 1435, scaled_rew : 7.90162, total_rew : 237.04865\n",
            "ep# 118 count :  534, scaled_rew : -0.74080, total_rew : -22.22407\n",
            "ep# 119 count :  474, scaled_rew : -1.22837, total_rew : -36.85112\n",
            "ep# 120 count :  269, scaled_rew : -2.77541, total_rew : -83.26220\n",
            "ep# 121 count :  572, scaled_rew : -1.50417, total_rew : -45.12522\n",
            "ep# 122 count : 1262, scaled_rew : 2.93994, total_rew : 88.19834\n",
            "ep# 123 count : 1088, scaled_rew : 1.50788, total_rew : 45.23625\n",
            "ep# 124 count :  653, scaled_rew : -0.94866, total_rew : -28.45994\n",
            "ep# 125 count : 1454, scaled_rew : 7.84212, total_rew : 235.26364\n",
            "ep# 126 count :  614, scaled_rew : -0.58224, total_rew : -17.46730\n",
            "ep# 127 count : 1392, scaled_rew : 7.96717, total_rew : 239.01515\n",
            "ep# 128 count :   68, scaled_rew : -3.62610, total_rew : -108.78304\n",
            "ep# 129 count :   72, scaled_rew : -3.60215, total_rew : -108.06463\n",
            "ep# 130 count :   73, scaled_rew : -3.73221, total_rew : -111.96619\n",
            "ep# 131 count : 1264, scaled_rew : 3.46208, total_rew : 103.86243\n",
            "ep# 132 count :  165, scaled_rew : -3.03716, total_rew : -91.11486\n",
            "ep# 133 count : 1293, scaled_rew : 8.26726, total_rew : 248.01772\n",
            "ep# 134 count : 1045, scaled_rew : 2.60454, total_rew : 78.13634\n",
            "ep# 135 count : 1290, scaled_rew : 8.25948, total_rew : 247.78447\n",
            "ep# 136 count :  207, scaled_rew : -3.34226, total_rew : -100.26793\n",
            "ep# 137 count :  688, scaled_rew : -0.42892, total_rew : -12.86755\n",
            "ep# 138 count :   84, scaled_rew : -3.22459, total_rew : -96.73765\n",
            "ep# 139 count : 1269, scaled_rew : 8.21142, total_rew : 246.34249\n",
            "ep# 140 count : 1154, scaled_rew : 8.48745, total_rew : 254.62353\n",
            "ep# 141 count : 1193, scaled_rew : 8.38478, total_rew : 251.54352\n",
            "ep# 142 count : 1174, scaled_rew : 8.39685, total_rew : 251.90539\n",
            "ep# 143 count : 1197, scaled_rew : 8.32894, total_rew : 249.86828\n",
            "ep# 144 count :  138, scaled_rew : -4.25441, total_rew : -127.63217\n",
            "ep# 145 count : 1136, scaled_rew : 8.52444, total_rew : 255.73307\n",
            "ep# 146 count : 1065, scaled_rew : 8.65890, total_rew : 259.76713\n",
            "ep# 147 count : 1081, scaled_rew : 8.60221, total_rew : 258.06619\n",
            "ep# 148 count : 1028, scaled_rew : 8.75425, total_rew : 262.62750\n",
            "ep# 149 count : 1113, scaled_rew : 8.54350, total_rew : 256.30500\n",
            "ep# 150 count :  197, scaled_rew : -3.96426, total_rew : -118.92780\n",
            "ep# 151 count :  130, scaled_rew : -4.50930, total_rew : -135.27898\n",
            "ep# 152 count :  916, scaled_rew : 4.50992, total_rew : 135.29768\n",
            "ep# 153 count :  195, scaled_rew : -3.68153, total_rew : -110.44580\n",
            "ep# 154 count :  838, scaled_rew : 1.72388, total_rew : 51.71651\n",
            "ep# 155 count :  114, scaled_rew : -4.32691, total_rew : -129.80719\n",
            "ep# 156 count : 1050, scaled_rew : 8.64768, total_rew : 259.43035\n",
            "ep# 157 count :  685, scaled_rew : 1.88898, total_rew : 56.66929\n",
            "ep# 158 count :  216, scaled_rew : -2.20740, total_rew : -66.22195\n",
            "ep# 159 count : 1070, scaled_rew : 8.60209, total_rew : 258.06266\n",
            "ep# 160 count :   92, scaled_rew : -4.32157, total_rew : -129.64704\n",
            "ep# 161 count :   96, scaled_rew : -3.50839, total_rew : -105.25157\n",
            "ep# 162 count :   78, scaled_rew : -3.41801, total_rew : -102.54043\n",
            "ep# 163 count :   88, scaled_rew : -3.39098, total_rew : -101.72943\n",
            "ep# 164 count : 1311, scaled_rew : 7.82496, total_rew : 234.74890\n",
            "ep# 165 count :  235, scaled_rew : -4.21976, total_rew : -126.59284\n",
            "ep# 166 count :   66, scaled_rew : -3.62351, total_rew : -108.70523\n",
            "ep# 167 count :  109, scaled_rew : -3.77766, total_rew : -113.32987\n",
            "ep# 168 count :  734, scaled_rew : 1.39969, total_rew : 41.99075\n",
            "ep# 169 count :  296, scaled_rew : -3.24833, total_rew : -97.44980\n",
            "ep# 170 count : 1035, scaled_rew : 8.73395, total_rew : 262.01847\n",
            "ep# 171 count : 1057, scaled_rew : 8.65116, total_rew : 259.53487\n",
            "ep# 172 count : 1017, scaled_rew : 8.74576, total_rew : 262.37276\n",
            "ep# 173 count :  192, scaled_rew : -2.98501, total_rew : -89.55041\n",
            "ep# 174 count : 1051, scaled_rew : 8.68130, total_rew : 260.43889\n",
            "ep# 175 count :   80, scaled_rew : -4.03396, total_rew : -121.01895\n",
            "ep# 176 count : 1035, scaled_rew : 8.68211, total_rew : 260.46341\n",
            "ep# 177 count : 1083, scaled_rew : 8.56473, total_rew : 256.94178\n",
            "ep# 178 count :  991, scaled_rew : 8.83416, total_rew : 265.02493\n",
            "ep# 179 count :   63, scaled_rew : -4.21414, total_rew : -126.42418\n",
            "ep# 180 count :  408, scaled_rew : -1.13096, total_rew : -33.92892\n",
            "ep# 181 count :  965, scaled_rew : 8.91636, total_rew : 267.49069\n",
            "ep# 182 count : 1017, scaled_rew : 8.73254, total_rew : 261.97617\n",
            "ep# 183 count :  495, scaled_rew : -1.57944, total_rew : -47.38305\n",
            "ep# 184 count :  974, scaled_rew : 8.89087, total_rew : 266.72620\n",
            "ep# 185 count :  994, scaled_rew : 8.85458, total_rew : 265.63752\n",
            "ep# 186 count :  965, scaled_rew : 8.89462, total_rew : 266.83871\n",
            "ep# 187 count :  974, scaled_rew : 8.87307, total_rew : 266.19217\n",
            "ep# 188 count :  957, scaled_rew : 8.93306, total_rew : 267.99184\n",
            "ep# 189 count :  974, scaled_rew : 8.85233, total_rew : 265.56994\n",
            "ep# 190 count :  291, scaled_rew : -1.54998, total_rew : -46.49933\n",
            "ep# 191 count :  948, scaled_rew : 8.97307, total_rew : 269.19196\n",
            "ep# 192 count :  940, scaled_rew : 8.98439, total_rew : 269.53156\n",
            "ep# 193 count :  343, scaled_rew : -0.79935, total_rew : -23.98062\n",
            "ep# 194 count :  936, scaled_rew : 8.97525, total_rew : 269.25750\n",
            "ep# 195 count :  977, scaled_rew : 8.85477, total_rew : 265.64314\n",
            "ep# 196 count :  948, scaled_rew : 8.95224, total_rew : 268.56711\n",
            "ep# 197 count :  912, scaled_rew : 9.06111, total_rew : 271.83321\n",
            "ep# 198 count :  903, scaled_rew : 9.08440, total_rew : 272.53201\n",
            "ep# 199 count :  924, scaled_rew : 9.02336, total_rew : 270.70074\n",
            "ep# 200 count :  309, scaled_rew : -0.83480, total_rew : -25.04400\n",
            "ep# 201 count :  385, scaled_rew : -0.55400, total_rew : -16.61990\n",
            "ep# 202 count :  907, scaled_rew : 9.11613, total_rew : 273.48394\n",
            "ep# 203 count :  914, scaled_rew : 9.03460, total_rew : 271.03800\n",
            "ep# 204 count :  915, scaled_rew : 9.04921, total_rew : 271.47644\n",
            "ep# 205 count :  876, scaled_rew : -6.62751, total_rew : -198.82518\n",
            "ep# 206 count :   54, scaled_rew : -3.87695, total_rew : -116.30855\n",
            "ep# 207 count :   56, scaled_rew : -3.85724, total_rew : -115.71719\n",
            "ep# 208 count :   69, scaled_rew : -3.92281, total_rew : -117.68443\n",
            "ep# 209 count :  899, scaled_rew : 9.08376, total_rew : 272.51282\n",
            "ep# 210 count :  958, scaled_rew : 8.91297, total_rew : 267.38912\n",
            "ep# 211 count :   84, scaled_rew : -4.00210, total_rew : -120.06292\n",
            "ep# 212 count :  154, scaled_rew : -4.08675, total_rew : -122.60238\n",
            "ep# 213 count :  136, scaled_rew : -4.12125, total_rew : -123.63738\n",
            "ep# 214 count :  920, scaled_rew : 9.04461, total_rew : 271.33845\n",
            "ep# 215 count :  908, scaled_rew : 9.08107, total_rew : 272.43217\n",
            "ep# 216 count :  902, scaled_rew : 9.11442, total_rew : 273.43245\n",
            "ep# 217 count :  492, scaled_rew : 1.18383, total_rew : 35.51495\n",
            "ep# 218 count :  888, scaled_rew : 9.18196, total_rew : 275.45879\n",
            "ep# 219 count :  899, scaled_rew : 9.12708, total_rew : 273.81225\n",
            "ep# 220 count :  305, scaled_rew : -1.04728, total_rew : -31.41842\n",
            "ep# 221 count :  352, scaled_rew : -0.35830, total_rew : -10.74910\n",
            "ep# 222 count :  145, scaled_rew : -3.03628, total_rew : -91.08833\n",
            "ep# 223 count :  291, scaled_rew : -1.52700, total_rew : -45.81014\n",
            "ep# 224 count :  911, scaled_rew : 9.07660, total_rew : 272.29794\n",
            "ep# 225 count :  540, scaled_rew : 1.55502, total_rew : 46.65065\n",
            "ep# 226 count :  541, scaled_rew : 0.87753, total_rew : 26.32597\n",
            "ep# 227 count :  909, scaled_rew : 9.09207, total_rew : 272.76197\n",
            "ep# 228 count :  898, scaled_rew : 9.13353, total_rew : 274.00577\n",
            "ep# 229 count :  873, scaled_rew : 9.19387, total_rew : 275.81600\n",
            "ep# 230 count :  889, scaled_rew : 9.17101, total_rew : 275.13030\n",
            "ep# 231 count :  907, scaled_rew : 9.13637, total_rew : 274.09114\n",
            "ep# 232 count :  886, scaled_rew : 9.17102, total_rew : 275.13071\n",
            "ep# 233 count :  873, scaled_rew : 9.19097, total_rew : 275.72924\n",
            "ep# 234 count :  860, scaled_rew : 9.18935, total_rew : 275.68058\n",
            "ep# 235 count :  124, scaled_rew : -2.89818, total_rew : -86.94525\n",
            "ep# 236 count :  886, scaled_rew : 9.15167, total_rew : 274.55009\n",
            "ep# 237 count :  159, scaled_rew : -3.70907, total_rew : -111.27197\n",
            "ep# 238 count :  191, scaled_rew : -2.67149, total_rew : -80.14470\n",
            "ep# 239 count :  617, scaled_rew : 1.28272, total_rew : 38.48169\n",
            "ep# 240 count :  875, scaled_rew : 9.16489, total_rew : 274.94667\n",
            "ep# 241 count :   66, scaled_rew : -3.76988, total_rew : -113.09644\n",
            "ep# 242 count :  550, scaled_rew : 1.55423, total_rew : 46.62688\n",
            "ep# 243 count :  715, scaled_rew : 3.97994, total_rew : 119.39822\n",
            "ep# 244 count :  978, scaled_rew : 4.80090, total_rew : 144.02704\n",
            "ep# 245 count :   66, scaled_rew : -4.13387, total_rew : -124.01618\n",
            "ep# 246 count :  298, scaled_rew : -1.41792, total_rew : -42.53763\n",
            "ep# 247 count :  878, scaled_rew : 9.13508, total_rew : 274.05246\n",
            "ep# 248 count :  871, scaled_rew : 9.17511, total_rew : 275.25344\n",
            "ep# 249 count :   76, scaled_rew : -3.61510, total_rew : -108.45308\n",
            "ep# 250 count :  869, scaled_rew : 9.19256, total_rew : 275.77668\n",
            "ep# 251 count :  319, scaled_rew : -0.99286, total_rew : -29.78587\n",
            "ep# 252 count :  893, scaled_rew : 9.09015, total_rew : 272.70447\n",
            "ep# 253 count :  511, scaled_rew : 1.09716, total_rew : 32.91472\n",
            "ep# 254 count :  791, scaled_rew : 4.59255, total_rew : 137.77647\n",
            "ep# 255 count :  871, scaled_rew : 9.16851, total_rew : 275.05530\n",
            "ep# 256 count :  912, scaled_rew : 9.01064, total_rew : 270.31917\n",
            "ep# 257 count :  153, scaled_rew : -3.28664, total_rew : -98.59907\n",
            "ep# 258 count :  846, scaled_rew : 9.23214, total_rew : 276.96429\n",
            "ep# 259 count :  917, scaled_rew : 8.99901, total_rew : 269.97016\n",
            "ep# 260 count :  192, scaled_rew : -2.62357, total_rew : -78.70714\n",
            "ep# 261 count :  360, scaled_rew : -0.97656, total_rew : -29.29672\n",
            "ep# 262 count :   89, scaled_rew : -4.38928, total_rew : -131.67834\n",
            "ep# 263 count :  913, scaled_rew : 9.00847, total_rew : 270.25402\n",
            "ep# 264 count :  855, scaled_rew : 9.13922, total_rew : 274.17667\n",
            "ep# 265 count :  882, scaled_rew : 9.10016, total_rew : 273.00481\n",
            "ep# 266 count :  489, scaled_rew : 0.95859, total_rew : 28.75784\n",
            "ep# 267 count :  362, scaled_rew : -0.73510, total_rew : -22.05292\n",
            "ep# 268 count :  903, scaled_rew : 9.04275, total_rew : 271.28235\n",
            "ep# 269 count :  851, scaled_rew : 9.20058, total_rew : 276.01737\n",
            "ep# 270 count :  911, scaled_rew : 9.02449, total_rew : 270.73482\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}