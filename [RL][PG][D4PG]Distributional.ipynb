{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "X1ATg2s26AhO",
    "outputId": "51e73a92-9347-45ef-905b-3d674c4ad499"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: box2d in c:\\users\\bk\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: box2d-kengz in c:\\users\\bk\\anaconda3\\lib\\site-packages (2.3.3)\n"
     ]
    }
   ],
   "source": [
    "!apt-get install swig\n",
    "!pip3 install box2d box2d-kengz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE6-lCM6oqv3"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "\n",
    "version = \"1.0.0\"\n",
    "\n",
    "StepInfo = namedtuple(\"StepInfo\", (\"obs\", \"act_v\", \"noise_v\", \"act\", \"last_obs\", \"rew\", \"done\", \"etc\", \"n\"))\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, env, actor, noise = None, max_step = None, device = None):\n",
    "        self.env = env\n",
    "        if max_step is not None:\n",
    "            self.env._max_episode_steps = max_step\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")            \n",
    "        self.actor = actor\n",
    "        self.noise = noise\n",
    "        self.device = device\n",
    "        \n",
    "        self.wait = -1\n",
    "        self.interval = -1\n",
    "        self.frame = None\n",
    "        \n",
    "        self.step_set = False\n",
    "        self.n_step = 1\n",
    "        self.gamma = 0.99\n",
    "        self.scale_factor = 1\n",
    "        self.bias=0\n",
    "        \n",
    "    def prepare(self, step_unroll, gamma, scale=1, bias=0):\n",
    "        self.step_set = True\n",
    "        self.n_step = step_unroll\n",
    "        self.gamma= gamma\n",
    "        self.scale_factor = scale\n",
    "        self.bias=bias\n",
    "        \n",
    "    def set_renderer(self, rend_wait=0, rend_interval=1, frame = None):\n",
    "        self.wait = rend_wait\n",
    "        self.interval = rend_interval\n",
    "        self.frame = frame\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env.close()\n",
    "        self.env.reset()\n",
    "        \n",
    "    def render(self, epoch):\n",
    "        if self.wait >= 0 and epoch < self.wait:\n",
    "            return\n",
    "        if self.interval >= 0 and epoch % self.interval == 0:\n",
    "            rend = self.env.render(\"rgb_array\")\n",
    "            if self.frame is not None:\n",
    "                self.frame.append(self.env.render(\"rgb_array\"))\n",
    "        \n",
    "    def episode(self, epoch):\n",
    "        assert self.step_set\n",
    "        buffer = []\n",
    "        self.obs = self.env.reset()\n",
    "        self.render(epoch)\n",
    "\n",
    "        total_rew = 0\n",
    "        total_rew_scaled = 0\n",
    "        count = 0\n",
    "        while True:\n",
    "            with torch.no_grad():\n",
    "                act_v = self.actor(torch.FloatTensor([self.obs]).to(self.device)).cpu().squeeze(0).numpy()\n",
    "                if self.noise is not None:\n",
    "                    noise_v = act_v + self.noise.get_noise()\n",
    "                else:\n",
    "                    noise_v = act_v\n",
    "                if self.env.action_space.shape:\n",
    "                    noise_v = noise_v.clip(self.env.action_space.low, self.env.action_space.high)\n",
    "                act = self.actor.get_action(noise_v)\n",
    "\n",
    "            next_obs, rew, done, etc = self.env.step(act)\n",
    "            obs = self.obs\n",
    "            self.obs = next_obs\n",
    "            count += 1\n",
    "\n",
    "            total_rew_scaled += rew\n",
    "            rew += self.bias\n",
    "            rew /= self.scale_factor\n",
    "            total_rew += rew\n",
    "\n",
    "            self.render(epoch)\n",
    "\n",
    "            buffer.append(StepInfo(obs, act_v, noise_v, act, next_obs, rew, done, etc, -1))\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "            if len(buffer) < self.n_step:\n",
    "                continue\n",
    "                \n",
    "            yield self.unroll_step(buffer)\n",
    "            buffer.pop(0)\n",
    "            \n",
    "        while len(buffer):\n",
    "            yield self.unroll_step(buffer)\n",
    "            buffer.pop(0)\n",
    "        print(\"ep#%4d\"%epoch, \"count : %4d, scaled_rew : %03.5f, total_rew : %03.5f\"%(count, total_rew, total_rew_scaled))\n",
    "        return\n",
    "\n",
    "    def unroll_step(self, buffer):\n",
    "        assert len(buffer)\n",
    "        \n",
    "        rews = list(map(lambda b:b.rew, buffer))\n",
    "        rews.reverse()\n",
    "        rew_sum = 0\n",
    "\n",
    "        for r in rews:\n",
    "            rew_sum*=self.gamma\n",
    "            rew_sum+=r\n",
    "            \n",
    "        done = buffer[-1].done if len(buffer) == self.n_step else True\n",
    "        return StepInfo(buffer[0].obs, buffer[0].act_v, buffer[0].noise_v, buffer[0].act, buffer[-1].last_obs, rew_sum, done, buffer[0].etc, len(buffer))\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NoiseMaker():\n",
    "    def __init__(self, action_size, n_type = None, param = None, decay = True):\n",
    "        self.action_size = action_size\n",
    "        self.state = np.zeros(action_size, dtype=np.float32)\n",
    "        self.count = 0\n",
    "        self.decay = decay\n",
    "        if n_type is None:\n",
    "            n_type = \"normal\"\n",
    "        self.type = n_type\n",
    "        \n",
    "        if param is None:\n",
    "            self.param = {\n",
    "                \"start\": 0.9,\n",
    "                \"end\":0.02,\n",
    "                \"decay\": 2000\n",
    "            }\n",
    "            if n_type ==\"ou\":\n",
    "                self.param[\"ou_mu\"] = 0.0\n",
    "                self.param[\"ou_th\"] = 0.15\n",
    "                self.param[\"ou_sig\"] = 0.2\n",
    "        else:\n",
    "            self.param = param\n",
    "            \n",
    "    def get_noise(self):\n",
    "        eps = self.param[\"end\"] + (self.param[\"start\"] - self.param[\"end\"]) * math.exp(-1*self.count/ self.param[\"decay\"])\n",
    "        \n",
    "        noise = np.random.normal(size=self.action_size)\n",
    "        if self.type == \"ou\":\n",
    "            self.state += self.param[\"ou_th\"] * (self.param[\"ou_mu\"] - self.state) + self.param[\"ou_sig\"] * noise\n",
    "            noise = self.state\n",
    "        if not self.decay:\n",
    "            eps = 1\n",
    "        self.count += 1\n",
    "            \n",
    "        return noise * eps\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Replay:\n",
    "    def __init__(self, size, prio = False, alph = 0.6, beta = 0.4):\n",
    "        self.memory = collections.deque(maxlen = size)\n",
    "        self.size = size\n",
    "        self.priorities = collections.deque(maxlen = size)\n",
    "        self.prio = prio\n",
    "        self.alph = alph if prio else 0\n",
    "        self.beta = beta if prio else 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def push(self, data):\n",
    "        self.memory.append(data)\n",
    "        self.count += 1\n",
    "        if self.prio:\n",
    "            max_prio = np.array(self.priorities).max() if len(self.priorities) else 1.\n",
    "            self.priorities.append(max_prio)\n",
    "        \n",
    "    def prepare(self, env):\n",
    "        pass\n",
    "        \n",
    "    def sample(self, size):\n",
    "        if self.prio:\n",
    "            probs = np.array(self.priorities, dtype=np.float32)\n",
    "            min_prio = np.array(self.priorities).min()\n",
    "            if min_prio < 1:\n",
    "                probs /= min_prio\n",
    "            probs = probs ** self.alph\n",
    "            probs /= probs.sum()\n",
    "        else:\n",
    "            probs = np.ones(len(self),) / len(self)\n",
    "        \n",
    "        indices = np.random.choice(len(self), size, p=probs)\n",
    "        sample = [self.memory[idx] for idx in indices]\n",
    "        \n",
    "        beta = 1. + (self.beta - 1.) * math.exp(-1 * self.count / self.size)\n",
    "        weights = (len(self) * probs[indices]) ** (-beta)\n",
    "        weights /= weights.sum()\n",
    "        \n",
    "        return sample, indices, weights\n",
    "        \n",
    "    def update_priorities(self, indices, prios):\n",
    "        if not self.prio:\n",
    "            return\n",
    "        prios += 1e-8\n",
    "        for idx, prio in zip(indices,prios):\n",
    "            self.priorities[idx] = prio\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYxEy8Q6oqwJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import math\n",
    "\n",
    "class NoiseLinear(nn.Linear):\n",
    "    def __init__(self, in_, out_, val = 0.017, bias = True):\n",
    "        super(NoiseLinear, self).__init__(in_,out_,bias)\n",
    "        self.sigma_weight = nn.Parameter(torch.full((out_, in_), val))\n",
    "        self.register_buffer(\"eps_weight\", torch.zeros(out_, in_))\n",
    "        if bias:\n",
    "            self.sigma_bias = nn.Parameter(torch.full((out_,), val))\n",
    "            self.register_buffer(\"eps_bias\", torch.zeros(out_))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = math.sqrt(1 / self.in_features)\n",
    "        self.weight.data.uniform_(-std, std)\n",
    "        self.bias.data.uniform_(-std, std)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.eps_weight.normal_()\n",
    "        bias = self.bias\n",
    "        if bias is not None:\n",
    "            self.eps_bias.normal_()\n",
    "            bias = bias + self.sigma_bias * self.eps_bias.data\n",
    "        return F.linear(x, self.weight + self.sigma_weight * self.eps_weight, bias)\n",
    "\n",
    "class targetNet(nn.Module):\n",
    "    def __init__(self, off_net):\n",
    "        super(targetNet, self).__init__()\n",
    "        self.net = copy.deepcopy(off_net)\n",
    "        self.off_net = off_net\n",
    "        \n",
    "    def alpha_update(self, alpha = 0.05):\n",
    "        for off, tgt in zip(self.off_net.parameters(), self.net.parameters()):\n",
    "            tgt.data.copy_(off.data*alpha + tgt.data*(1-alpha))\n",
    "    \n",
    "    def copy_off_net(self):\n",
    "        self.net.load_state_dict(self.off_net.state_dict())\n",
    "    \n",
    "    def forward(self, *x):\n",
    "        return self.net(*x)\n",
    "        \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, in_, act_n, action_provider, hidden=512):\n",
    "        super(Actor, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, int(hidden/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden/2), act_n),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.action_provider = action_provider\n",
    "        \n",
    "    def get_action(self, act_v):\n",
    "        return self.action_provider(act_v)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DistCritic(nn.Module):\n",
    "    def __init__(self, in_, act_v, atom=51, hidden=512):\n",
    "        super(DistCritic, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_, hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.net_out = nn.Sequential(\n",
    "            nn.Linear(hidden + act_n, int(hidden/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden/2), atom)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs, act):\n",
    "        return self.net_out(torch.cat([self.net(obs), act], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJrRlHDroqwm"
   },
   "outputs": [],
   "source": [
    "V_MAX = 10\n",
    "V_MIN = -5\n",
    "ATOMS = 51\n",
    "V_DIST = (V_MAX-V_MIN)/(ATOMS-1)\n",
    "\n",
    "def transform_dist(dist, rew, gamma, unroll_n, done):\n",
    "    support_start = V_MIN\n",
    "    \n",
    "    dist = dist.cpu().detach().numpy()\n",
    "    ret = np.zeros_like(dist)\n",
    "    rew = rew.cpu().numpy()\n",
    "    unroll_n = unroll_n.cpu().numpy()\n",
    "    done = done.cpu().numpy()\n",
    "    for atom in range(ATOMS):\n",
    "        support = support_start + atom * V_DIST\n",
    "        next_support = rew + (gamma**unroll_n) * support\n",
    "        next_support[next_support > V_MAX] = V_MAX\n",
    "        next_support[next_support < V_MIN] = V_MIN\n",
    "\n",
    "        indices = ((next_support - V_MIN) / V_DIST).squeeze()\n",
    "        l = np.floor(indices).astype(np.int64)\n",
    "        r = np.ceil(indices).astype(np.int64)\n",
    "\n",
    "        eq = l==r\n",
    "        ret[eq, l[eq]] += dist[eq, atom]\n",
    "        neq = l!=r\n",
    "        ret[neq, l[neq]] += dist[neq, atom] * (r - indices)[neq]\n",
    "        ret[neq, r[neq]] += dist[neq, atom] * (indices - l)[neq]\n",
    "\n",
    "        if done.any():\n",
    "            ret[done] = 0.0\n",
    "            next_support = rew[done]\n",
    "            next_support[next_support > V_MAX] = V_MAX\n",
    "            next_support[next_support < V_MIN] = V_MIN\n",
    "\n",
    "            indices = ((next_support - V_MIN) / V_DIST).squeeze()\n",
    "            l = np.floor(indices).astype(np.int64)\n",
    "            r = np.ceil(indices).astype(np.int64)\n",
    "\n",
    "            eq = l==r\n",
    "            eq_done = done.copy()\n",
    "            eq_done[done] = eq\n",
    "            if eq_done.any():\n",
    "                ret[eq_done, l[eq]] = 1.0\n",
    "\n",
    "            neq = l!=r\n",
    "            neq_done = done.copy()\n",
    "            neq_done[done] = neq\n",
    "            if neq_done.any():\n",
    "                ret[neq_done, l[neq]] = (r - indices)[neq]\n",
    "                ret[neq_done, r[neq]] = (indices - l)[neq]\n",
    "            \n",
    "    return torch.FloatTensor(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "DxDEeOCfoqwd",
    "outputId": "dd6e5425-5e73-41ce-a4a8-5a1b872b19dd"
   },
   "outputs": [
    {
     "ename": "DeprecatedEnv",
     "evalue": "Env BipedalWalker-v3 not found (valid versions include ['BipedalWalker-v2'])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mspec\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'BipedalWalker-v3'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDeprecatedEnv\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-16858b727f75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BipedalWalker-v3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mact_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mobs_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mmake\u001b[1;34m(id, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mmake\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Making new env: %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# We used to have people override _reset/_step rather than\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mspec\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    138\u001b[0m                              if env_name == valid_env_spec._env_name]\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmatching_envs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeprecatedEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Env {} not found (valid versions include {})'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatching_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnregisteredEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No registered env with id: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDeprecatedEnv\u001b[0m: Env BipedalWalker-v3 not found (valid versions include ['BipedalWalker-v2'])"
     ]
    }
   ],
   "source": [
    "ACT_LR = 0.001\n",
    "CRT_LR = 0.001\n",
    "GAMMA = 0.99\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")     \n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\")\n",
    "act_n = env.action_space.shape[0]\n",
    "obs_n = env.observation_space.shape[0]\n",
    "\n",
    "actor = Actor(obs_n, act_n, lambda x:x).to(device)\n",
    "actor_tgt = targetNet(actor)\n",
    "actor_optim = optim.Adam(actor.parameters(), ACT_LR)\n",
    "\n",
    "critic = DistCritic(obs_n, act_n, ATOMS).to(device)\n",
    "critic_tgt = targetNet(critic)\n",
    "critic_optim = optim.Adam(critic.parameters(), CRT_LR)\n",
    "\n",
    "ST_SIZE = 50000\n",
    "ST_INIT = 10000\n",
    "ST_DECAY = 5000\n",
    "BATCH = 512\n",
    "\n",
    "storage = Replay(ST_SIZE, True)\n",
    "noise = NoiseMaker(act_n, \"ou\", decay=True)\n",
    "noise.param[\"ou_sig\"] = 0.6\n",
    "noise.param[\"decay\"] = ST_SIZE\n",
    "\n",
    "agent = Agent(env, actor, noise, device=device)\n",
    "agent.prepare(3, GAMMA, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Vvt1_9i0oqxQ",
    "outputId": "aa2b7252-2290-40e4-ebb3-1f9929de0801",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "EPOCH = 2000\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for i, step in enumerate(agent.episode(epoch)):\n",
    "        storage.push(step)\n",
    "        if len(storage) < ST_INIT:\n",
    "            continue\n",
    "            \n",
    "        sample, indices, weights = storage.sample(BATCH)\n",
    "        weights_ = torch.FloatTensor(weights).to(device)\n",
    "        obs, act_v, noise_v, act, next_obs, rew, done, etc, unroll_n = list(zip(*sample))\n",
    "        \n",
    "        obs_ = torch.FloatTensor(obs).to(device)\n",
    "        act_v_ = torch.FloatTensor(act_v).to(device)\n",
    "        noise_v_ = torch.FloatTensor(noise_v).to(device)\n",
    "        act_ = torch.LongTensor(act).unsqueeze(1).to(device)\n",
    "        next_obs_ = torch.FloatTensor(next_obs).to(device)\n",
    "        rew_ = torch.FloatTensor(rew).unsqueeze(1).to(device)\n",
    "        done_ = torch.BoolTensor(done).to(device)\n",
    "        unroll_n_ = torch.FloatTensor(unroll_n).unsqueeze(1).to(device)\n",
    "\n",
    "        #Critic update\n",
    "        critic_optim.zero_grad()\n",
    "        q_pred = critic(obs_, noise_v_)\n",
    "        \n",
    "        q_next_prob = critic_tgt(next_obs_, actor_tgt(next_obs_))\n",
    "        q_next = F.softmax(q_next_prob, dim=1)\n",
    "        q_target = transform_dist(q_next, rew_, GAMMA, unroll_n_, done_).to(device)\n",
    "\n",
    "        q_entropy = -F.log_softmax(q_pred, dim=1) * q_target\n",
    "        q_entropy_sum = q_entropy.sum(dim=1)\n",
    "        q_loss = (weights_ * q_entropy_sum).sum()\n",
    "        q_loss.backward()\n",
    "        critic_optim.step()\n",
    "\n",
    "        storage.update_priorities(indices, q_entropy_sum.cpu().detach().numpy())\n",
    "\n",
    "        #Actor update\n",
    "        actor_optim.zero_grad()\n",
    "        \n",
    "        #history decaying\n",
    "        st_decay = torch.exp_(-torch.FloatTensor(len(storage)-indices)/ST_DECAY).unsqueeze(1).to(device)\n",
    "        act_avg = actor(obs_) * (1-st_decay) + act_v_ * st_decay\n",
    "        q_dist = critic(obs_,act_avg)\n",
    "        \n",
    "        q_v = -F.softmax(q_dist,dim=1) * torch.arange(V_MIN, V_MAX + V_DIST - 1e-8, V_DIST).to(device)\n",
    "        q_v = q_v.mean(dim=1)\n",
    "\n",
    "        actor_loss = q_v.mean()\n",
    "        actor_loss.backward()\n",
    "        actor_optim.step()\n",
    "\n",
    "        #target update\n",
    "        critic_tgt.alpha_update()\n",
    "        actor_tgt.alpha_update()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
