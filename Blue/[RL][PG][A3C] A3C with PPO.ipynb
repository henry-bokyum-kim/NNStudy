{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "env._max_episode_steps = 400\n",
    "\n",
    "obs_n = env.observation_space.shape[0]\n",
    "act_n = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "step = namedtuple('step', ('obs', 'act_v', 'act', 'next_obs', 'v_value', 'done'))\n",
    "\n",
    "def get_episode(env, net, batch, proc, train_queue):\n",
    "    obs = env.reset()\n",
    "    ep = list()\n",
    "    \n",
    "    count = 0\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            act_v, _ = net(torch.FloatTensor(obs))\n",
    "        act = np.random.choice(act_n, p=F.softmax(act_v, dim=0).detach().numpy())\n",
    "        act_v = act_v.detach().numpy()\n",
    "        \n",
    "        next_obs, rew, done, _ = env.step(act)\n",
    "        with torch.no_grad():\n",
    "            _, v_value = net(torch.FloatTensor(next_obs))\n",
    "        count += 1\n",
    "        ep.append(step(obs, act_v, act, next_obs, rew + (0 if done else GAMMA*v_value.item()), done))\n",
    "        obs = next_obs\n",
    "        \n",
    "        if done:\n",
    "            print(proc, count)\n",
    "            count = 0\n",
    "            obs = env.reset()\n",
    "            \n",
    "        if len(ep) != batch:\n",
    "            continue\n",
    "\n",
    "        steps = step(*zip(*ep))\n",
    "\n",
    "        obs_ = torch.FloatTensor(steps.obs)\n",
    "        act_ = torch.LongTensor(steps.act)\n",
    "        act_v_ = torch.FloatTensor(steps.act_v)\n",
    "        v_value_ = torch.FloatTensor(steps.v_value)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logit, v_pred = net(obs_)\n",
    "\n",
    "        # critic update\n",
    "        critic_loss = F.mse_loss(v_pred.squeeze(-1), v_value_)\n",
    "        critic_loss.backward()\n",
    "\n",
    "        # actor update\n",
    "        prob = F.softmax(logit, dim=1)\n",
    "        log_prob = F.log_softmax(logit, dim=1)\n",
    "\n",
    "        adv = v_value_.unsqueeze(1) - v_pred.detach()\n",
    "        # adv_pos = adv > 0\n",
    "        # adv_neg = adv < 0\n",
    "        # prob_old_g = F.softmax(act_v_, dim=1).gather(1, act_.unsqueeze(1))\n",
    "        # prob_g = prob.gather(1, act_.unsqueeze(1))\n",
    "\n",
    "        # ratio = prob_g/prob_old_g\n",
    "        # ratio[adv_pos] = ratio[adv_pos].clamp_max(1+EPS)\n",
    "        # ratio[adv_neg] = ratio[adv_neg].clamp_min(1-EPS)\n",
    "        # policy_loss = (ratio * adv).mean()\n",
    "        policy_loss = (-log_prob * adv).mean()\n",
    "\n",
    "        # entropy loss\n",
    "        entropy_loss = (prob * log_prob).sum(dim=1).mean()\n",
    "\n",
    "        actor_loss = policy_loss + ALPHA * entropy_loss\n",
    "        actor_loss.backward()\n",
    "\n",
    "        #print(\"[%3d]\"%proc + \"policy : %.7f entrophy : %.7f critic : %.7f\\n\"%(policy_loss, entropy_loss, critic_loss))\n",
    "        \n",
    "        train_queue.put([p.grad.data.cpu() for p in net.parameters()])\n",
    "        ep = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "class A2C(nn.Module):\n",
    "    def __init__(self, in_, out_, hidden=512):\n",
    "        super(A2C, self).__init__()\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(in_, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, out_),\n",
    "        )\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(in_, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.actor(x), self.critic(x)\n",
    "    \n",
    "GAMMA = 0.99\n",
    "ALPHA = 0.01\n",
    "LR = 0.0001\n",
    "BATCH = 64\n",
    "QUEUE_SIZE = 8\n",
    "TGT_UP = 8\n",
    "EPOCH = 100000\n",
    "EPS = 0.2\n",
    "\n",
    "net = A2C(obs_n, act_n)\n",
    "opt = optim.Adam(net.parameters(), LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-23b98fa28cac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprocess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_episode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mprocess_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    net.share_memory()\n",
    "\n",
    "    train_queue = mp.Queue(maxsize=QUEUE_SIZE)\n",
    "    process_list = []\n",
    "    for i in range(QUEUE_SIZE):\n",
    "        env = gym.make(\"CartPole-v1\")\n",
    "        env.reset()\n",
    "        env._max_episode_steps = 400\n",
    "\n",
    "        obs_n = env.observation_space.shape[0]\n",
    "        act_n = env.action_space.n\n",
    "\n",
    "        process = mp.Process(target = get_episode, args=(env, net, BATCH, i, train_queue))\n",
    "        process.start()\n",
    "        process_list.append(process)\n",
    "        \n",
    "    grad_tgt = None\n",
    "    for epoch in range(EPOCH):\n",
    "        \n",
    "        grad_ = train_queue.get()\n",
    "        if grad_tgt is None:\n",
    "            grad_tgt = grad_\n",
    "        else:\n",
    "            for tgt, g in zip(grad_tgt, grad_):\n",
    "                tgt += g\n",
    "                \n",
    "        if epoch % TGT_UP == TGT_UP - 1:\n",
    "            grad_sum = []\n",
    "            for net_grad, tgt in zip(net.parameters(), grad_tgt):\n",
    "                net_grad.grad = torch.FloatTensor(tgt)\n",
    "                grad_sum.append(net_grad.grad.data.sum().item())\n",
    "            opt.step()\n",
    "            grad_tgt = None\n",
    "            \n",
    "            print(\"EPOCH %d]\"%epoch, end= \" \")\n",
    "            for g in grad_sum:\n",
    "                print(\"%.5f\"%g, end=' ')\n",
    "            print()\n",
    "    \n",
    "    for p in process_list:\n",
    "        p.terminate()\n",
    "        p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
