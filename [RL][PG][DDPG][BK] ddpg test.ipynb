{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "cdfklxV-HIsM",
    "outputId": "fe90c6bf-44e2-46cc-a45d-ae2501e46866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-430\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  libxxf86dga1\n",
      "Suggested packages:\n",
      "  mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  libxxf86dga1 x11-utils\n",
      "0 upgraded, 2 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 209 kB of archives.\n",
      "After this operation, 711 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
      "Fetched 209 kB in 1s (226 kB/s)\n",
      "Selecting previously unselected package libxxf86dga1:amd64.\n",
      "(Reading database ... 145113 files and directories currently installed.)\n",
      "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
      "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
      "Unpacking x11-utils (7.7+3build1) ...\n",
      "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Setting up x11-utils (7.7+3build1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "!apt-get install x11-utils\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "id": "PPLX39f1IIOR",
    "outputId": "4af0ccc7-9039-4d75-f65a-a6e7c03fba96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-430\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  xvfb\n",
      "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 783 kB of archives.\n",
      "After this operation, 2,266 kB of additional disk space will be used.\n",
      "Err:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.3\n",
      "  404  Not Found [IP: 91.189.88.24 80]\n",
      "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/universe/x/xorg-server/xvfb_1.19.6-1ubuntu4.3_amd64.deb  404  Not Found [IP: 91.189.88.24 80]\n",
      "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
     ]
    }
   ],
   "source": [
    "!apt-get install xvfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiZUJW5TK_HX"
   },
   "outputs": [],
   "source": [
    "v_display = Display(visible=0, size=(1400,900),)\n",
    "v_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "colab_type": "code",
    "id": "3xdhZ0_SLRCP",
    "outputId": "3407ddac-4584-4f0e-a335-c65a33e435f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-430\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  swig3.0\n",
      "Suggested packages:\n",
      "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
      "The following NEW packages will be installed:\n",
      "  swig swig3.0\n",
      "0 upgraded, 2 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 1,100 kB of archives.\n",
      "After this operation, 5,822 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
      "Fetched 1,100 kB in 1s (836 kB/s)\n",
      "Selecting previously unselected package swig3.0.\n",
      "(Reading database ... 145167 files and directories currently installed.)\n",
      "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
      "Unpacking swig3.0 (3.0.12-1) ...\n",
      "Selecting previously unselected package swig.\n",
      "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
      "Unpacking swig (3.0.12-1) ...\n",
      "Setting up swig3.0 (3.0.12-1) ...\n",
      "Setting up swig (3.0.12-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Collecting box2d\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/7b/ddb96fea1fa5b24f8929714ef483f64c33e9649e7aae066e5f5023ea426a/Box2D-2.3.2.tar.gz (427kB)\n",
      "\u001b[K     |████████████████████████████████| 430kB 4.7MB/s \n",
      "\u001b[?25hCollecting box2d-kengz\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/20/51d6c0c87f7642efb709c518fb0ca8e5eab068259588552c41da5926ae27/Box2D-kengz-2.3.3.tar.gz (425kB)\n",
      "\u001b[K     |████████████████████████████████| 430kB 59.7MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: box2d, box2d-kengz\n",
      "  Building wheel for box2d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for box2d: filename=Box2D-2.3.2-cp36-cp36m-linux_x86_64.whl size=2012758 sha256=9cc8476f50b6be95c408a342855d92f346398e1ddaf5b4c132cb9e0ecece6572\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/09/fd/054e73da7184a08071ed889bf45772719c7bb6d2dd13f166a1\n",
      "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp36-cp36m-linux_x86_64.whl size=2012908 sha256=1a1228dd564f16fff238b55c132395af588bf2be9a0349ac8bafbdfd3528a72a\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/ae/e5/8bc678d262caad94659c199c540550e59d03dd3bd3684d4f1a\n",
      "Successfully built box2d box2d-kengz\n",
      "Installing collected packages: box2d, box2d-kengz\n",
      "Successfully installed box2d-2.3.2 box2d-kengz-2.3.3\n"
     ]
    }
   ],
   "source": [
    "!apt-get install swig\n",
    "!pip3 install box2d box2d-kengz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzaLXqsqJ6Db"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import collections\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omoh29dxJ6Dg"
   },
   "outputs": [],
   "source": [
    "step = namedtuple(\"step\", (\"state\", \"action\", \"next_state\", \"reward\", \"done\"))\n",
    "\n",
    "class Replay:\n",
    "    def __init__(self, size):\n",
    "        self.memory = collections.deque(maxlen = size)\n",
    "        \n",
    "    def push(self, data):\n",
    "        self.memory.append(data)\n",
    "        \n",
    "    def prepare(self, env):\n",
    "        pass\n",
    "        \n",
    "    def sample(self, size):\n",
    "        if len(self.memory) >= size:\n",
    "            return random.sample(self.memory, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osS_PNCMLlRL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NoiseMaker():\n",
    "    def __init__(self, action_size, n_type = None, param = None):\n",
    "        self.action_size = action_size\n",
    "        self.state = np.zeros(action_size, dtype=np.float32)\n",
    "        self.count = 0\n",
    "        if n_type is None:\n",
    "            n_type = \"normal\"\n",
    "        self.type = n_type\n",
    "        \n",
    "        if param is None:\n",
    "            self.param = {\n",
    "                \"start\": 0.9,\n",
    "                \"end\":0.02,\n",
    "                \"decay\": 100000\n",
    "            }\n",
    "            if n_type ==\"ou\":\n",
    "                self.param[\"ou_mu\"] = 0.0\n",
    "                self.param[\"ou_th\"] = 0.15\n",
    "                self.param[\"ou_sig\"] = 0.2\n",
    "        else:\n",
    "            self.param = param\n",
    "            \n",
    "    def get_noise(self, n_type = None, decay = False):\n",
    "        n_type = n_type if n_type is not None else self.type\n",
    "        eps = self.param[\"end\"] + (self.param[\"start\"] - self.param[\"end\"]) \\\n",
    "                * math.exp(-1*self.count/ self.param[\"decay\"])\n",
    "        \n",
    "        noise = np.random.normal(size=self.action_size)\n",
    "        if n_type == \"ou\":\n",
    "            self.state += self.param[\"ou_th\"] * (self.param[\"ou_mu\"] - self.state) \\\n",
    "                        + self.param[\"ou_sig\"] * noise\n",
    "            noise = self.state\n",
    "        if not decay:\n",
    "            eps = 1\n",
    "        self.count += 1\n",
    "            \n",
    "        return noise * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYRqH1BsJ6Di"
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_n, action_n, hidden = 512):\n",
    "        super(Actor, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_n, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, int(hidden/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden/2), action_n),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_n, action_n, hidden = 512):\n",
    "        super(Critic, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_n, hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden+action_n, int(hidden/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden/2), 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state, act):\n",
    "        temp = self.net(state)\n",
    "        return self.out(torch.cat([temp, act], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "KIOu1OrnJ6Dl",
    "outputId": "7f545e10-25a2-4eb6-b021-9643a21e454a"
   },
   "outputs": [],
   "source": [
    "EPOCH = 5000\n",
    "GAME_NAME = \"LunarLander-v2\"\n",
    "\n",
    "env = gym.make(GAME_NAME)\n",
    "#env._max_episode_steps = 1000\n",
    "obs_n = env.observation_space.shape[0]\n",
    "act_n = env.action_space.n\n",
    "\n",
    "LR_ACT = 0.00008\n",
    "LR_CRT = 0.0004\n",
    "TAU = 0.05\n",
    "GAMMA = 0.99\n",
    "\n",
    "actor = Actor(obs_n, act_n).cuda()\n",
    "actor_optim = optim.Adam(actor.parameters(), lr = LR_ACT)\n",
    "actor_tgt = Actor(obs_n, act_n).cuda()\n",
    "actor_tgt.load_state_dict(actor.state_dict())\n",
    "\n",
    "critic = Critic(obs_n, act_n).cuda()\n",
    "critic_optim = optim.Adam(critic.parameters(), lr = LR_CRT)\n",
    "critic_tgt = Critic(obs_n, act_n).cuda()\n",
    "critic_tgt.load_state_dict(critic.state_dict())\n",
    "\n",
    "MAX_MEMORY = 100000\n",
    "MEM_INIT = 2000\n",
    "BATCH = 512\n",
    "storage = Replay(MAX_MEMORY)\n",
    "noise = NoiseMaker(act_n, \"ou\")\n",
    "\n",
    "VIDEO_WAIT = 1000\n",
    "VIDEO = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise.count = summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nJmlM4p3J6Dn",
    "outputId": "34870b1d-00f7-4984-bc6e-1c66812fcd20",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 count 252 300.69425740780036\n",
      "epoch 1 count 275 -191.48367051171977\n",
      "epoch 2 count 262 246.91178809955184\n",
      "epoch 3 count 236 290.4586856427619\n",
      "epoch 4 count 143 289.5263781782646\n",
      "epoch 5 count 154 264.93302474411905\n",
      "epoch 6 count 231 274.6465413655658\n",
      "epoch 7 count 159 258.6247696091885\n",
      "epoch 8 count 188 268.98512617079973\n",
      "epoch 9 count 187 260.3091344634463\n",
      "epoch 10 count 381 -106.49625944920655\n",
      "epoch 11 count 159 241.09284913520176\n",
      "epoch 12 count 100 51.39588912047884\n",
      "epoch 13 count 330 283.23504755220307\n",
      "epoch 14 count 449 -319.88063711113546\n",
      "epoch 15 count 173 278.2878131474773\n",
      "epoch 16 count 154 -120.84175154424818\n",
      "epoch 17 count 294 -284.6371413199164\n",
      "epoch 18 count 177 247.75992419043124\n",
      "epoch 19 count 191 263.8736235568001\n",
      "epoch 20 count 99 4.041229861814585\n",
      "epoch 21 count 294 266.1405867639112\n",
      "epoch 22 count 172 264.68025743763087\n",
      "epoch 23 count 105 -0.48640870669332514\n",
      "epoch 24 count 159 259.0281838886669\n",
      "epoch 25 count 248 294.14397963098946\n",
      "epoch 26 count 284 -233.9172924327061\n",
      "epoch 27 count 188 297.50828429641945\n",
      "epoch 28 count 190 305.6236643974246\n",
      "epoch 29 count 197 265.06795918911564\n",
      "epoch 30 count 367 -403.9221922467241\n",
      "epoch 31 count 516 208.4829291615876\n",
      "epoch 32 count 188 252.50447482933362\n",
      "epoch 33 count 229 290.70025323968014\n",
      "epoch 34 count 101 43.040866346754854\n",
      "epoch 35 count 189 289.506216686519\n",
      "epoch 36 count 337 231.57868532081483\n",
      "epoch 37 count 366 -92.00408448904247\n",
      "epoch 38 count 296 -129.96995492970325\n",
      "epoch 39 count 95 34.765669916008164\n",
      "epoch 40 count 394 190.4210785080591\n",
      "epoch 41 count 350 263.607014776503\n",
      "epoch 42 count 316 279.6397602785434\n",
      "epoch 43 count 195 273.36354355405496\n",
      "epoch 44 count 129 278.13140081961143\n",
      "epoch 45 count 163 259.5327045922713\n",
      "epoch 46 count 125 58.89944457765816\n",
      "epoch 47 count 1000 -54.70010580929006\n",
      "epoch 48 count 598 284.54856843838627\n",
      "epoch 49 count 232 306.33926956849973\n",
      "epoch 50 count 208 263.63283753228075\n",
      "epoch 51 count 300 269.50507540158355\n",
      "epoch 52 count 69 18.930819049339917\n",
      "epoch 53 count 360 253.26805401994594\n",
      "epoch 54 count 192 275.42241584518285\n",
      "epoch 55 count 195 281.7406234884401\n",
      "epoch 56 count 230 274.8905035886176\n",
      "epoch 57 count 506 233.96182721139968\n",
      "epoch 58 count 312 -348.3760006191749\n",
      "epoch 59 count 218 284.4236745645698\n",
      "epoch 60 count 225 290.926621467126\n",
      "epoch 61 count 95 40.138330175297256\n",
      "epoch 62 count 172 267.67840484019644\n",
      "epoch 63 count 203 278.75548404152164\n",
      "epoch 64 count 183 265.76561792487826\n",
      "epoch 65 count 168 282.26774711220185\n",
      "epoch 66 count 1000 41.4103461873299\n",
      "epoch 67 count 97 36.80417169272681\n",
      "epoch 68 count 279 256.0602523706367\n",
      "epoch 69 count 171 300.9381594099454\n",
      "epoch 70 count 224 282.69648872864815\n",
      "epoch 71 count 371 203.27490960419362\n",
      "epoch 72 count 204 304.1764326892774\n",
      "epoch 73 count 184 248.3080264660247\n",
      "epoch 74 count 226 298.96895300938576\n",
      "epoch 75 count 234 294.84664677361036\n",
      "epoch 76 count 258 249.1863925287729\n",
      "epoch 77 count 245 309.95421917079585\n",
      "epoch 78 count 138 266.66695466679835\n",
      "epoch 79 count 134 7.246303441282919\n",
      "epoch 80 count 209 222.02512755794268\n",
      "epoch 81 count 154 256.07659261073525\n",
      "epoch 82 count 156 258.07071016223387\n",
      "epoch 83 count 632 294.55756378427225\n",
      "epoch 84 count 190 256.62632143903\n",
      "epoch 85 count 1000 62.00447259320274\n",
      "epoch 86 count 147 293.92909868471344\n",
      "epoch 87 count 181 273.860525897662\n",
      "epoch 88 count 258 237.0806253555253\n",
      "epoch 89 count 149 270.17920697125834\n",
      "epoch 90 count 1000 69.74486172055411\n",
      "epoch 91 count 221 291.77655259039057\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a0e4feb806c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mactor_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mactor_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactor_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mactor_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mactor_optim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frame = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    obs = env.reset()\n",
    "    env.render()\n",
    "    \n",
    "    count = 0\n",
    "    rew_total = 0\n",
    "    act_dis = [0,0,0]\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            act_v = actor(torch.FloatTensor(obs).cuda()).cpu().numpy()\n",
    "            act_v += noise.get_noise(\"ou\", True)\n",
    "            act_v = act_v.clip(-1, 1)\n",
    "            act = act_v.argmax()\n",
    "            \n",
    "        next_obs, rew, done, _ = env.step(act)\n",
    "        env.render()\n",
    "        rew_total += rew\n",
    "        count += 1\n",
    "        \n",
    "        storage.push(step(obs, act_v, next_obs, rew, done))\n",
    "        obs = next_obs\n",
    "        \n",
    "        sample = storage.sample(BATCH)\n",
    "        if sample:\n",
    "            sample = step(*zip(*sample))\n",
    "            \n",
    "            states = torch.FloatTensor(sample.state).cuda()\n",
    "            actions = torch.FloatTensor(sample.action).cuda()\n",
    "            next_states = torch.FloatTensor(sample.next_state).cuda()\n",
    "            rewards = torch.FloatTensor(sample.reward).unsqueeze(-1).cuda()\n",
    "            dones = torch.BoolTensor(sample.done).unsqueeze(-1).cuda()\n",
    "            \n",
    "            # critic learning\n",
    "            critic_optim.zero_grad()\n",
    "            q_pred = critic(states, actions)\n",
    "            \n",
    "            next_action_v = actor_tgt(next_states)\n",
    "            q_next = critic_tgt(next_states, next_action_v)\n",
    "            q_next[dones] = 0\n",
    "            q_target = rewards + GAMMA * q_next\n",
    "            \n",
    "            critic_loss = F.mse_loss(q_pred, q_target.detach())\n",
    "            critic_loss.backward()\n",
    "            critic_optim.step()\n",
    "            \n",
    "            # actor learning\n",
    "            actor_optim.zero_grad()\n",
    "            actor_loss = -critic(states, actor(states))\n",
    "            actor_loss = actor_loss.mean()\n",
    "            actor_loss.backward()\n",
    "            actor_optim.step()\n",
    "            \n",
    "            # tgt soft update\n",
    "            for tgt, real  in zip(actor_tgt.parameters(), actor.parameters()):\n",
    "                tgt.data.copy_(TAU*real.data + (1-TAU)*tgt.data)\n",
    "                \n",
    "            for tgt, real  in zip(critic_tgt.parameters(),critic.parameters()):\n",
    "                tgt.data.copy_(TAU*real.data + (1-TAU)*tgt.data)\n",
    "            \n",
    "        if done:\n",
    "            break\n",
    "    print(\"epoch %d count %d\"%(epoch, count), rew_total)\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjE62yZJZifl"
   },
   "outputs": [],
   "source": [
    "VIDEO_WAIT = 0\n",
    "VIDEO = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ar3zf2XEP4fi"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/content/gdrive/My Drive/critic_tgt','wb') as f:\n",
    "    pickle.dump(critic_tgt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsU2HET9uqgO"
   },
   "outputs": [],
   "source": [
    "!pip install JSAnimation\n",
    "from matplotlib import animation\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports specifically so we can render outputs in Colab.\n",
    "def display_frames_as_gif(frame, intv=30):\n",
    "    \"\"\"Displays a list of frames as a gif, with controls.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frame[0].astype(int))\n",
    "    def animate(i):\n",
    "        patch.set_data(frame[i].astype(int))\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, animate, frames=len(frame), interval=intv, blit=False\n",
    "    )\n",
    "    #display(display_animation(anim, default_mode='loop'))\n",
    "    # Set up formatting for the movie files\n",
    "    display(HTML(data=anim.to_html5_video()))\n",
    "    #FFwriter = animation.FFMpegWriter()\n",
    "    #anim.save('basic_animation.mp4', writer = FFwriter)\n",
    "    #show_video()\n",
    "# display \n",
    "\n",
    "display_frames_as_gif(frame)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "[RL][PG][DDPG][BK] ddpg test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
