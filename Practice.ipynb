{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Practice.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwwaS--8KTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "outputId": "c44d915f-0be4-4f51-9fc4-59fd5c3baf57"
      },
      "source": [
        "get_ipython().system('pip install gym pyvirtualdisplay > /dev/null 2>&1')\n",
        "get_ipython().system('apt-get update ')\n",
        "get_ipython().system('apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1')\n",
        "get_ipython().system('apt-get install x11-utils')\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "v_display = Display(visible=0, size=(1400,900),)\n",
        "v_display.start()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.31)] [1 InRelease 0 B/88.7 kB 0\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.31)] [1 InRelease 14.2 kB/88.7 \r0% [Connecting to archive.ubuntu.com (91.189.88.31)] [1 InRelease 28.7 kB/88.7 \r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [1 InRelease 28.7 kB/88.7 k\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [1 InRelease 43.1 kB/88.7 k\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rGet:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [5 In\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [5 InRelease 14.2 kB/21.3 k\r                                                                               \rGet:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [5 InRelease 14.2 kB/21.3 k\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [5 InRelease 14.2 kB/21.3 k\r                                                                               \rGet:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [819 B]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [9 Release.gpg 819 B/819 B \r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [5 InRelease 14.2 kB/21.3 k\r                                                                               \rGet:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [10 InRelease 2,601 B/88.7 kB 3%] [5 InRelease 14\r0% [2 InRelease gpgv 3,626 B] [10 InRelease 5,497 B/88.7 kB 6%] [Connecting to \r0% [10 InRelease 15.6 kB/88.7 kB 18%] [Connecting to ppa.launchpad.net (91.189.\r0% [1 InRelease gpgv 88.7 kB] [10 InRelease 15.6 kB/88.7 kB 18%] [Connecting to\r                                                                               \rGet:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [10 InRelease 53.3 kB/88.7 kB 60%] [11 InRelease \r                                                                               \r0% [10 InRelease 63.4 kB/88.7 kB 71%] [11 InRelease 15.4 kB/15.4 kB 100%]\r                                                                         \r0% [10 InRelease 63.4 kB/88.7 kB 71%]\r0% [4 InRelease gpgv 242 kB] [10 InRelease 63.4 kB/88.7 kB 71%] [Waiting for he\r                                                                               \r0% [4 InRelease gpgv 242 kB] [Waiting for headers]\r                                                  \rGet:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [836 kB]\n",
            "\r0% [4 InRelease gpgv 242 kB] [Waiting for headers] [12 Packages 2,687 B/836 kB \r                                                                               \rGet:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [4 InRelease gpgv 242 kB] [13 InRelease 2,601 B/74.6 kB 3%] [12 Packages 389\r                                                                               \r0% [4 InRelease gpgv 242 kB] [13 InRelease 70.7 kB/74.6 kB 95%]\r0% [12 Packages store 0 B] [4 InRelease gpgv 242 kB] [13 InRelease 70.7 kB/74.6\r                                                                               \r0% [12 Packages store 0 B] [4 InRelease gpgv 242 kB] [Waiting for headers]\r                                                                          \r0% [12 Packages store 0 B] [Waiting for headers]\r                                                \rGet:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [826 kB]\n",
            "\r                                                \r0% [12 Packages store 0 B]\r0% [12 Packages store 0 B] [Release.gpg gpgv 564 B]\r                                                   \r0% [Release.gpg gpgv 564 B]\r0% [14 Packages store 0 B] [Release.gpg gpgv 564 B]\r                                                   \r0% [Release.gpg gpgv 564 B]\r                           \r0% [Working]\r0% [9 Release.gpg gpgv 564 B]\r                             \r0% [Working]\r0% [5 InRelease gpgv 21.3 kB] [Waiting for headers]\r                                                   \rGet:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [141 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.1 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,355 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,782 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,128 kB]\n",
            "Get:21 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [860 kB]\n",
            "Fetched 7,261 kB in 3s (2,090 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils\n",
            "0 upgraded, 2 newly installed, 0 to remove and 84 not upgraded.\n",
            "Need to get 209 kB of archives.\n",
            "After this operation, 711 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Fetched 209 kB in 1s (312 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 147480 files and directories currently installed.)\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUTrycae8Eo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import namedtuple\n",
        "\n",
        "version = \"1.0.0\"\n",
        "\n",
        "StepInfo = namedtuple(\"StepInfo\", (\"obs\", \"act_v\", \"noise_v\", \"act\", \"last_obs\", \"rew\", \"done\", \"etc\", \"n\"))\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, env, actor, noise = None, max_step = None, device=None):\n",
        "        self.env = env\n",
        "        if max_step is not None:\n",
        "            self.env._max_episode_steps = max_step           \n",
        "        self.actor = actor\n",
        "        self.noise = noise\n",
        "        self.device = device\n",
        "        \n",
        "        self.wait = -1\n",
        "        self.interval = -1\n",
        "        self.frame = None\n",
        "        \n",
        "        self.step_set = False\n",
        "        self.n_step = 1\n",
        "        self.gamma = 0.99\n",
        "        self.scale_factor = 1\n",
        "        self.bias=0\n",
        "        \n",
        "    def prepare(self, step_unroll, gamma, cnn=False, scale=1, bias=0):\n",
        "        self.step_set = True\n",
        "        self.n_step = step_unroll\n",
        "        self.gamma= gamma\n",
        "        self.scale_factor = scale\n",
        "        self.bias=bias\n",
        "        self.cnn = cnn\n",
        "        \n",
        "    def set_renderer(self, rend_wait=0, rend_interval=1, frame = None):\n",
        "        self.wait = rend_wait\n",
        "        self.interval = rend_interval\n",
        "        self.frame = frame\n",
        "        \n",
        "    def reset(self):\n",
        "        self.env.close()\n",
        "        self.env.reset()\n",
        "        \n",
        "    def render(self, epoch):\n",
        "        if self.wait >= 0 and epoch < self.wait:\n",
        "            return\n",
        "        if self.interval >= 0 and epoch % self.interval == 0:\n",
        "            rend = self.env.render(\"rgb_array\")\n",
        "            if self.frame is not None:\n",
        "                self.frame.append(self.env.render(\"rgb_array\"))\n",
        "        \n",
        "    def episode(self, epoch):\n",
        "        assert self.step_set\n",
        "        t=time.time()\n",
        "        buffer = []\n",
        "        self.obs = self.env.reset()\n",
        "        if self.cnn:\n",
        "            self.obs = self.actor.convert_input(self.env.render(\"rgb_array\"))\n",
        "        else:\n",
        "            self.render(epoch)\n",
        "\n",
        "        total_rew = 0\n",
        "        total_rew_scaled = 0\n",
        "        count = 0\n",
        "        while True:\n",
        "            with torch.no_grad():\n",
        "                out = self.actor(torch.FloatTensor([self.obs]).to(self.device))\n",
        "                act_v = out[0] if type(out) is tuple else out\n",
        "                act_v = act_v.cpu().squeeze(0).numpy()\n",
        "                if self.noise is not None:\n",
        "                    noise_v = act_v + self.noise.get_noise()\n",
        "                else:\n",
        "                    noise_v = act_v\n",
        "                if self.env.action_space.shape:\n",
        "                    noise_v = noise_v.clip(self.env.action_space.low, self.env.action_space.high)\n",
        "                act = self.actor.convert_to_action(noise_v)\n",
        "\n",
        "            next_obs, rew, done, etc = self.env.step(act)\n",
        "            obs = self.obs\n",
        "            next_obs = self.actor.convert_input(self.env.render(\"rgb_array\")) if self.cnn else next_obs\n",
        "            self.obs = next_obs\n",
        "            count += 1\n",
        "\n",
        "            total_rew_scaled += rew\n",
        "            rew += self.bias\n",
        "            rew /= self.scale_factor\n",
        "            total_rew += rew\n",
        "\n",
        "            self.render(epoch)\n",
        "\n",
        "            buffer.append(StepInfo(obs, act_v, noise_v, act, next_obs, rew, done, etc, -1))\n",
        "            if done:\n",
        "                break\n",
        "                \n",
        "            if len(buffer) < self.n_step:\n",
        "                continue\n",
        "                \n",
        "            yield self.unroll_step(buffer)\n",
        "            buffer.pop(0)\n",
        "            \n",
        "        while len(buffer):\n",
        "            yield self.unroll_step(buffer)\n",
        "            buffer.pop(0)\n",
        "        print(\"ep#%4d]\"%epoch, \"elapsed : %.2f, count : %4d, scaled_rew : %03.5f, total_rew : %03.5f\"%(time.time()-t, count, total_rew, total_rew_scaled))\n",
        "        return\n",
        "\n",
        "    def unroll_step(self, buffer):\n",
        "        assert len(buffer)\n",
        "        \n",
        "        rews = list(map(lambda b:b.rew, buffer))\n",
        "        rews.reverse()\n",
        "        rew_sum = 0\n",
        "\n",
        "        for r in rews:\n",
        "            rew_sum*=self.gamma\n",
        "            rew_sum+=r\n",
        "            \n",
        "        done = buffer[-1].done if len(buffer) == self.n_step else True\n",
        "        return StepInfo(buffer[0].obs, buffer[0].act_v, buffer[0].noise_v, buffer[0].act, buffer[-1].last_obs, rew_sum, done, buffer[0].etc, len(buffer))\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class NoiseMaker():\n",
        "    def __init__(self, action_size, n_type = None, param = None, decay = True):\n",
        "        self.action_size = action_size\n",
        "        self.state = np.zeros(action_size, dtype=np.float32)\n",
        "        self.count = 0\n",
        "        self.decay = decay\n",
        "        if n_type is None:\n",
        "            n_type = \"normal\"\n",
        "        self.type = n_type\n",
        "        \n",
        "        if param is None:\n",
        "            self.param = {\n",
        "                \"start\": 0.9,\n",
        "                \"end\":0.02,\n",
        "                \"decay\": 2000\n",
        "            }\n",
        "            if n_type ==\"ou\":\n",
        "                self.param[\"ou_mu\"] = 0.0\n",
        "                self.param[\"ou_th\"] = 0.15\n",
        "                self.param[\"ou_sig\"] = 0.2\n",
        "        else:\n",
        "            self.param = param\n",
        "            \n",
        "    def get_noise(self):\n",
        "        eps = self.param[\"end\"] + (self.param[\"start\"] - self.param[\"end\"]) * math.exp(-1*self.count/ self.param[\"decay\"])\n",
        "        \n",
        "        noise = np.random.normal(size=self.action_size)\n",
        "        if self.type == \"ou\":\n",
        "            self.state += self.param[\"ou_th\"] * (self.param[\"ou_mu\"] - self.state) + self.param[\"ou_sig\"] * noise\n",
        "            noise = self.state\n",
        "        if not self.decay:\n",
        "            eps = 1\n",
        "        self.count += 1\n",
        "            \n",
        "        return noise * eps\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class Replay:\n",
        "    def __init__(self, init, size, prio = False, alph = 0.6, beta = 0.4):\n",
        "        self.memory = collections.deque(maxlen = size)\n",
        "        self.init = init\n",
        "        self.size = size\n",
        "        self.priorities = collections.deque(maxlen = size)\n",
        "        self.prio = prio\n",
        "        self.alph = alph if prio else 0\n",
        "        self.beta = beta if prio else 0\n",
        "        self.count = 0\n",
        "        \n",
        "    def push(self, data):\n",
        "        self.memory.append(data)\n",
        "        self.count += 1\n",
        "        if self.prio:\n",
        "            max_prio = np.array(self.priorities).max() if len(self.priorities) else 1.\n",
        "            self.priorities.append(max_prio)\n",
        "        \n",
        "    def is_ready(self):\n",
        "        return len(self) >= self.init\n",
        "        \n",
        "    def sample(self, size):\n",
        "        if self.prio:\n",
        "            probs = np.array(self.priorities, dtype=np.float32)\n",
        "            min_prio = np.array(self.priorities).min()\n",
        "            if min_prio < 1:\n",
        "                probs /= min_prio\n",
        "            probs = probs ** self.alph\n",
        "            probs /= probs.sum()\n",
        "        else:\n",
        "            probs = np.ones(len(self),) / len(self)\n",
        "        \n",
        "        indices = np.random.choice(len(self), size, p=probs)\n",
        "        sample = [self.memory[idx] for idx in indices]\n",
        "        \n",
        "        beta = 1. + (self.beta - 1.) * math.exp(-1 * self.count / self.size)\n",
        "        weights = (len(self) * probs[indices]) ** (-beta)\n",
        "        weights /= weights.sum()\n",
        "        \n",
        "        return sample, indices, weights\n",
        "        \n",
        "    def update_priorities(self, indices, prios):\n",
        "        if not self.prio:\n",
        "            return\n",
        "        prios += 1e-8\n",
        "        for idx, prio in zip(indices,prios):\n",
        "            self.priorities[idx] = prio\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "    \n",
        "import torch.nn as nn\n",
        "import copy\n",
        "\n",
        "class targetNet(nn.Module):\n",
        "    def __init__(self, off_net):\n",
        "        super(targetNet, self).__init__()\n",
        "        self.net = copy.deepcopy(off_net)\n",
        "        self.off_net = off_net\n",
        "        \n",
        "    def alpha_update(self, alpha = 0.05):\n",
        "        for off, tgt in zip(self.off_net.parameters(), self.net.parameters()):\n",
        "            tgt.data.copy_(off.data*alpha + tgt.data*(1-alpha))\n",
        "    \n",
        "    def copy_off_net(self):\n",
        "        self.net.load_state_dict(self.off_net.state_dict())\n",
        "    \n",
        "    def forward(self, *x):\n",
        "        return self.net(*x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzJ6JWB48EpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo6FSJY78Epu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, act_n, shape, hidden = 512):\n",
        "        super(Actor, self).__init__()\n",
        "        cnn_out_channel = 64\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, cnn_out_channel, 4, 2, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        w = self.get_conv_out_size(shape[1])\n",
        "        h = self.get_conv_out_size(shape[2])\n",
        "        self.cnn_out = w*h*cnn_out_channel\n",
        "        \n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(self.cnn_out, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, int(hidden/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(hidden/2), act_n),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return super(Actor,self).to(device)\n",
        "        \n",
        "    def convert_input(self, x):\n",
        "        return x[165:330].transpose(2,0,1)\n",
        "        \n",
        "    def convert_to_action(self, act_v):\n",
        "        return act_v.argmax()\n",
        "        \n",
        "    def get_conv_out_size(self, value):\n",
        "        return int(int(int(value/2)/2)/2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        cnn_out = self.cnn(x).view(-1,self.cnn_out)\n",
        "        return self.actor(cnn_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYBGzFK1a2BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, act_n, shape, hidden = 512):\n",
        "        super(Critic, self).__init__()\n",
        "        cnn_out_channel = 64\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, cnn_out_channel, 4, 2, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        w = self.get_conv_out_size(shape[1])\n",
        "        h = self.get_conv_out_size(shape[2])\n",
        "        self.cnn_out = w*h*cnn_out_channel\n",
        "        \n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(self.cnn_out, hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.critic_out = nn.Sequential(\n",
        "            nn.Linear(hidden + act_n, int(hidden/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(hidden/2), 1)\n",
        "        )\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return super(Critic,self).to(device)\n",
        "        \n",
        "    def convert_input(self, x):\n",
        "        return x[165:330].transpose(2,0,1)\n",
        "        \n",
        "    def convert_to_action(self, act_v):\n",
        "        return act_v.argmax()\n",
        "        \n",
        "    def get_conv_out_size(self, value):\n",
        "        return int(int(int(value/2)/2)/2)\n",
        "    \n",
        "    def forward(self, x, act_v=None):\n",
        "        cnn_out = self.cnn(x).view(-1,self.cnn_out)\n",
        "        return self.critic_out(torch.cat([self.critic(cnn_out), act_v],dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJhr-PUe8Ep3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c0261118-2878-4048-ac66-3ea5a23da00c"
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")\n",
        "act_n = env.action_space.n\n",
        "obs_n = env.observation_space.shape[0]\n",
        "\n",
        "env.reset()\n",
        "r = (env.render(\"rgb_array\")[165:330].transpose(2,0,1))\n",
        "env.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeC7sd9T8EqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h46folze8Eqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "8533bb36-a27a-4d10-f9c8-e0667bb53438"
      },
      "source": [
        "plt.imshow(r.transpose(1,2,0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7d31622a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAB/CAYAAAAU5IInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2x3rLPw8ErE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 0.001\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "actor= Actor(act_n, r.shape).to(device)\n",
        "actor_tgt = targetNet(actor)\n",
        "actor_opt = optim.Adam(actor.parameters(), LR)\n",
        "critic= Critic(act_n, r.shape).to(device)\n",
        "critic_tgt = targetNet(critic)\n",
        "critic_opt = optim.Adam(critic.parameters(), LR)\n",
        "\n",
        "GAMMA = 0.99\n",
        "\n",
        "noise = NoiseMaker(act_n, \"normal\", decay = True)\n",
        "noise.param[\"ou_sig\"] = 0.6\n",
        "agent = Agent(env, actor, noise, 500, device=device)\n",
        "agent.prepare(2, GAMMA, True)\n",
        "\n",
        "ST_SIZE = 10000\n",
        "ST_INIT = 2000\n",
        "ST_DECAY = 2000\n",
        "ST_BATCH = 64\n",
        "storage = Replay(ST_INIT, ST_SIZE, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWvnbpQ-8ErQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e157fcb-3ab5-4d91-dcc4-4e63447d430a"
      },
      "source": [
        "EPOCH = 1000\n",
        "for epoch in range(EPOCH):\n",
        "    for step in agent.episode(epoch):\n",
        "        storage.push(step)\n",
        "        if not storage.is_ready():\n",
        "            continue\n",
        "        \n",
        "        sample, indices, weights = storage.sample(ST_BATCH)\n",
        "        weights_ = torch.FloatTensor(weights).unsqueeze(1).to(device)\n",
        "        obs, act_v, noise_v, act, next_obs, rew, done, etc, unroll_n = list(zip(*sample))\n",
        "        \n",
        "        obs_ = torch.FloatTensor(obs).to(device)\n",
        "        act_v_ = torch.FloatTensor(act_v).to(device)\n",
        "        noise_v_ = torch.FloatTensor(noise_v).to(device)\n",
        "        act_ = torch.LongTensor(act).unsqueeze(1).to(device)\n",
        "        next_obs_ = torch.FloatTensor(next_obs).to(device)\n",
        "        rew_ = torch.FloatTensor(rew).unsqueeze(1).to(device)\n",
        "        done_ = torch.BoolTensor(done).to(device)\n",
        "        unroll_n_ = torch.FloatTensor(unroll_n).unsqueeze(1).to(device)\n",
        "\n",
        "        #critic\n",
        "        critic_opt.zero_grad()\n",
        "        q_pred = critic(obs_, noise_v_)\n",
        "        \n",
        "        q_next = critic_tgt(next_obs_, actor_tgt(next_obs_))\n",
        "        q_next[done_] = 0.\n",
        "        q_target = rew_ + (GAMMA ** unroll_n_) * q_next.detach()\n",
        "        \n",
        "        q_loss = weights_ * (q_next - q_target) ** 2\n",
        "        q_loss.mean().backward()\n",
        "        critic_opt.step()\n",
        "        \n",
        "        storage.update_priorities(indices, q_loss.detach().cpu().numpy())\n",
        "        \n",
        "        #actor\n",
        "        actor_opt.zero_grad()\n",
        "        st_decay = torch.exp_(-torch.FloatTensor(len(storage)-indices)/ST_DECAY).unsqueeze(1).to(device)\n",
        "        act_avg = actor(obs_) * (1-st_decay) + act_v_ * st_decay\n",
        "\n",
        "        q_v = -critic(obs_, act_avg)\n",
        "\n",
        "        actor_loss = q_v.mean()\n",
        "        actor_loss.backward()\n",
        "        actor_opt.step()\n",
        "        \n",
        "        #target_update\n",
        "        actor_tgt.alpha_update()\n",
        "        critic_tgt.alpha_update()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ep#   0] elapsed : 0.76, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#   1] elapsed : 0.61, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#   2] elapsed : 0.86, count :   20, scaled_rew : 20.00000, total_rew : 20.00000\n",
            "ep#   3] elapsed : 0.54, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#   4] elapsed : 0.69, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#   5] elapsed : 0.71, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#   6] elapsed : 0.44, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#   7] elapsed : 0.60, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#   8] elapsed : 0.78, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#   9] elapsed : 0.98, count :   24, scaled_rew : 24.00000, total_rew : 24.00000\n",
            "ep#  10] elapsed : 0.64, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  11] elapsed : 0.58, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  12] elapsed : 0.75, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  13] elapsed : 0.79, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  14] elapsed : 0.60, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  15] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  16] elapsed : 0.68, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  17] elapsed : 0.82, count :   20, scaled_rew : 20.00000, total_rew : 20.00000\n",
            "ep#  18] elapsed : 1.31, count :   31, scaled_rew : 31.00000, total_rew : 31.00000\n",
            "ep#  19] elapsed : 0.80, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  20] elapsed : 0.54, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  21] elapsed : 1.03, count :   24, scaled_rew : 24.00000, total_rew : 24.00000\n",
            "ep#  22] elapsed : 0.70, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  23] elapsed : 0.63, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  24] elapsed : 0.63, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  25] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  26] elapsed : 0.63, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  27] elapsed : 0.95, count :   22, scaled_rew : 22.00000, total_rew : 22.00000\n",
            "ep#  28] elapsed : 0.98, count :   21, scaled_rew : 21.00000, total_rew : 21.00000\n",
            "ep#  29] elapsed : 0.64, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  30] elapsed : 0.54, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  31] elapsed : 0.41, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  32] elapsed : 0.58, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  33] elapsed : 1.08, count :   25, scaled_rew : 25.00000, total_rew : 25.00000\n",
            "ep#  34] elapsed : 0.64, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  35] elapsed : 0.65, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  36] elapsed : 0.80, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  37] elapsed : 0.40, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  38] elapsed : 0.62, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  39] elapsed : 0.40, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  40] elapsed : 0.90, count :   21, scaled_rew : 21.00000, total_rew : 21.00000\n",
            "ep#  41] elapsed : 0.68, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  42] elapsed : 0.60, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  43] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  44] elapsed : 0.69, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  45] elapsed : 0.46, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  46] elapsed : 0.67, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  47] elapsed : 0.46, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  48] elapsed : 0.61, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  49] elapsed : 0.59, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  50] elapsed : 0.37, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  51] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  52] elapsed : 0.38, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  53] elapsed : 1.50, count :   35, scaled_rew : 35.00000, total_rew : 35.00000\n",
            "ep#  54] elapsed : 0.60, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  55] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  56] elapsed : 0.51, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  57] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  58] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  59] elapsed : 0.58, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  60] elapsed : 0.67, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  61] elapsed : 0.95, count :   21, scaled_rew : 21.00000, total_rew : 21.00000\n",
            "ep#  62] elapsed : 0.44, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  63] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  64] elapsed : 0.60, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  65] elapsed : 1.68, count :   35, scaled_rew : 35.00000, total_rew : 35.00000\n",
            "ep#  66] elapsed : 0.62, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  67] elapsed : 0.88, count :   20, scaled_rew : 20.00000, total_rew : 20.00000\n",
            "ep#  68] elapsed : 0.63, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  69] elapsed : 0.43, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  70] elapsed : 0.98, count :   21, scaled_rew : 21.00000, total_rew : 21.00000\n",
            "ep#  71] elapsed : 0.64, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  72] elapsed : 0.51, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  73] elapsed : 1.11, count :   24, scaled_rew : 24.00000, total_rew : 24.00000\n",
            "ep#  74] elapsed : 0.50, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  75] elapsed : 0.41, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  76] elapsed : 0.88, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  77] elapsed : 0.47, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  78] elapsed : 0.90, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  79] elapsed : 0.56, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  80] elapsed : 0.60, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  81] elapsed : 0.74, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  82] elapsed : 1.02, count :   21, scaled_rew : 21.00000, total_rew : 21.00000\n",
            "ep#  83] elapsed : 0.74, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  84] elapsed : 0.69, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  85] elapsed : 1.01, count :   22, scaled_rew : 22.00000, total_rew : 22.00000\n",
            "ep#  86] elapsed : 0.66, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  87] elapsed : 0.87, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  88] elapsed : 0.73, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  89] elapsed : 0.66, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  90] elapsed : 0.44, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  91] elapsed : 0.51, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  92] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  93] elapsed : 0.58, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  94] elapsed : 0.60, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  95] elapsed : 0.46, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  96] elapsed : 0.58, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  97] elapsed : 0.61, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  98] elapsed : 0.71, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  99] elapsed : 0.56, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep# 100] elapsed : 0.68, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep# 101] elapsed : 0.89, count :   20, scaled_rew : 20.00000, total_rew : 20.00000\n",
            "ep# 102] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep# 103] elapsed : 0.49, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep# 104] elapsed : 0.57, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep# 105] elapsed : 0.91, count :   21, scaled_rew : 21.00000, total_rew : 21.00000\n",
            "ep# 106] elapsed : 0.50, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep# 107] elapsed : 0.62, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep# 108] elapsed : 0.35, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep# 109] elapsed : 0.57, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep# 110] elapsed : 0.77, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep# 111] elapsed : 0.42, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 112] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 113] elapsed : 0.44, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 114] elapsed : 0.79, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep# 115] elapsed : 0.41, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 116] elapsed : 0.40, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 117] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 118] elapsed : 0.49, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep# 119] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 120] elapsed : 0.53, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 121] elapsed : 0.69, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep# 122] elapsed : 0.57, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep# 123] elapsed : 0.45, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 124] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 125] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 126] elapsed : 0.64, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep# 127] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 128] elapsed : 0.46, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 129] elapsed : 0.53, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep# 130] elapsed : 0.57, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep# 131] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 132] elapsed : 0.45, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 133] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 134] elapsed : 0.35, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep# 135] elapsed : 0.36, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep# 136] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 137] elapsed : 0.54, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep# 138] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep# 139] elapsed : 0.40, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 140] elapsed : 0.35, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "4.707178831100464\n",
            "0.057441383600234985 -0.7932619452476501\n",
            "4.685839891433716\n",
            "0.06028379499912262 -0.7813080549240112\n",
            "ep# 141] elapsed : 11.99, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "4.73102593421936\n",
            "0.059623826295137405 -0.7739454507827759\n",
            "5.30597186088562\n",
            "0.058849483728408813 -0.7908076047897339\n",
            "4.840841770172119\n",
            "0.05748048424720764 -0.7907966375350952\n",
            "4.873942613601685\n",
            "0.0609884113073349 -0.7885634303092957\n",
            "4.849533557891846\n",
            "0.05612851679325104 -0.7960781455039978\n",
            "4.851408243179321\n",
            "0.057111937552690506 -0.7923657298088074\n",
            "4.904297351837158\n",
            "0.058986809104681015 -0.7744516730308533\n",
            "4.9104979038238525\n",
            "0.057601623237133026 -0.7833786010742188\n",
            "4.936415672302246\n",
            "0.058947473764419556 -0.7911800146102905\n",
            "4.8872785568237305\n",
            "0.05619870126247406 -0.7797926664352417\n",
            "ep# 142] elapsed : 57.84, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "4.9233527183532715\n",
            "0.05635084584355354 -0.7767053842544556\n",
            "4.8877177238464355\n",
            "0.05855695158243179 -0.779644250869751\n",
            "4.943189382553101\n",
            "0.055490732192993164 -0.8087325096130371\n",
            "4.9168736934661865\n",
            "0.05709380656480789 -0.7944649457931519\n",
            "4.923008441925049\n",
            "0.058732952922582626 -0.7982441782951355\n",
            "4.8742430210113525\n",
            "0.05637412890791893 -0.7870575189590454\n",
            "5.065662622451782\n",
            "0.05554777383804321 -0.7987876534461975\n",
            "4.968501806259155\n",
            "0.05623728781938553 -0.7894845604896545\n",
            "4.928090572357178\n",
            "0.05871687829494476 -0.7884513139724731\n",
            "ep# 143] elapsed : 52.30, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "4.884411573410034\n",
            "0.05876828357577324 -0.7972455024719238\n",
            "4.934289455413818\n",
            "0.05669975280761719 -0.7878698110580444\n",
            "4.865135908126831\n",
            "0.05758107453584671 -0.7906288504600525\n",
            "4.995318174362183\n",
            "0.054658494889736176 -0.7813142538070679\n",
            "4.872728586196899\n",
            "0.05786482244729996 -0.7884849309921265\n",
            "4.92542576789856\n",
            "0.059593234211206436 -0.793928325176239\n",
            "4.9184112548828125\n",
            "0.058238476514816284 -0.7692824602127075\n",
            "4.936228513717651\n",
            "0.058379776775836945 -0.7816618084907532\n",
            "ep# 144] elapsed : 46.35, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "4.970423460006714\n",
            "0.05748622119426727 -0.7748396992683411\n",
            "4.9604268074035645\n",
            "0.0601639598608017 -0.7816702127456665\n",
            "4.919097900390625\n",
            "0.057808153331279755 -0.7842251062393188\n",
            "4.8995444774627686\n",
            "0.05913621187210083 -0.7875913381576538\n",
            "4.890594482421875\n",
            "0.059623174369335175 -0.7952975034713745\n",
            "4.847784757614136\n",
            "0.058319274336099625 -0.7724690437316895\n",
            "4.993748426437378\n",
            "0.06099133566021919 -0.7802428007125854\n",
            "4.8932390213012695\n",
            "0.06016472727060318 -0.7859216928482056\n",
            "ep# 145] elapsed : 46.39, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "4.896202087402344\n",
            "0.05939289182424545 -0.7797658443450928\n",
            "4.880546808242798\n",
            "0.05915526673197746 -0.7814096212387085\n",
            "4.879928827285767\n",
            "0.06103833019733429 -0.7808178663253784\n",
            "4.878357172012329\n",
            "0.058927834033966064 -0.783866286277771\n",
            "4.90699577331543\n",
            "0.059582240879535675 -0.7856587171554565\n",
            "4.837773323059082\n",
            "0.06096196174621582 -0.7886437773704529\n",
            "4.908092260360718\n",
            "0.059881363064050674 -0.7827553749084473\n",
            "4.8759379386901855\n",
            "0.05754031240940094 -0.7890112400054932\n",
            "4.9010231494903564\n",
            "0.05577380955219269 -0.7776292562484741\n",
            "4.8765528202056885\n",
            "0.05831180885434151 -0.7812975645065308\n",
            "ep# 146] elapsed : 57.60, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "4.881279468536377\n",
            "0.05559562146663666 -0.7758613228797913\n",
            "4.810121536254883\n",
            "0.05950644984841347 -0.7903296947479248\n",
            "4.938127517700195\n",
            "0.05858459323644638 -0.7909479141235352\n",
            "4.896946907043457\n",
            "0.0596918985247612 -0.7742451429367065\n",
            "4.928853511810303\n",
            "0.06072327122092247 -0.7847014665603638\n",
            "4.817405700683594\n",
            "0.06088747829198837 -0.8035368919372559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk0TuHuKghQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q_loss"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}