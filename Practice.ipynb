{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Practice.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwwaS--8KTr",
        "colab_type": "code",
        "outputId": "efb1133c-2784-4e78-809a-ad4fdca7417e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "get_ipython().system('pip install gym pyvirtualdisplay > /dev/null 2>&1')\n",
        "get_ipython().system('apt-get update ')\n",
        "get_ipython().system('apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1')\n",
        "get_ipython().system('apt-get install x11-utils')\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "v_display = Display(visible=0, size=(1400,900),)\n",
        "v_display.start()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.14)] [Co\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.14)] [Co\r0% [1 InRelease gpgv 21.3 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 21.3 kB] [3 InRelease 2,604 B/88.7 kB 3%] [Connecting to s\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "\r0% [1 InRelease gpgv 21.3 kB] [3 InRelease 2,604 B/88.7 kB 3%] [Connecting to s\r                                                                               \rHit:5 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 21.3 kB] [3 InRelease 2,604 B/88.7 kB 3%] [Connecting to s\r0% [1 InRelease gpgv 21.3 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [1 InRelease gpgv 21.3 kB] [6 InRelease 11.3 kB/74.6 kB 15%] [Waiting for he\r                                                                               \r0% [1 InRelease gpgv 21.3 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r                                                                         \r0% [1 InRelease gpgv 21.3 kB] [Waiting for headers]\r                                                   \r0% [Waiting for headers]\r0% [2 InRelease gpgv 242 kB] [Waiting for headers]\r                                                  \rIgn:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 242 kB] [Waiting for headers]\r                                                  \r0% [Waiting for headers]\r0% [4 InRelease gpgv 3,626 B] [Waiting for headers]\r                                                   \rIgn:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                   \r0% [4 InRelease gpgv 3,626 B]\r                             \rHit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [4 InRelease gpgv 3,626 B]\r                             \rHit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 163 kB in 1s (119 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUTrycae8Eo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import namedtuple\n",
        "\n",
        "version = \"1.0.0\"\n",
        "\n",
        "StepInfo = namedtuple(\"StepInfo\", (\"obs\", \"act_v\", \"noise_v\", \"act\", \"last_obs\", \"rew\", \"done\", \"etc\", \"n\"))\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, env, actor, noise = None, max_step = None, device=None):\n",
        "        self.env = env\n",
        "        if max_step is not None:\n",
        "            self.env._max_episode_steps = max_step           \n",
        "        self.actor = actor\n",
        "        self.noise = noise\n",
        "        self.device = device\n",
        "        \n",
        "        self.wait = -1\n",
        "        self.interval = -1\n",
        "        self.frame = None\n",
        "        \n",
        "        self.step_set = False\n",
        "        self.n_step = 1\n",
        "        self.gamma = 0.99\n",
        "        self.scale_factor = 1\n",
        "        self.bias=0\n",
        "        \n",
        "    def prepare(self, step_unroll, gamma, cnn=False, scale=1, bias=0):\n",
        "        self.step_set = True\n",
        "        self.n_step = step_unroll\n",
        "        self.gamma= gamma\n",
        "        self.scale_factor = scale\n",
        "        self.bias=bias\n",
        "        self.cnn = cnn\n",
        "        \n",
        "    def set_renderer(self, rend_wait=0, rend_interval=1, frame = None):\n",
        "        self.wait = rend_wait\n",
        "        self.interval = rend_interval\n",
        "        self.frame = frame\n",
        "        \n",
        "    def reset(self):\n",
        "        self.env.close()\n",
        "        self.env.reset()\n",
        "        \n",
        "    def render(self, epoch):\n",
        "        if self.wait >= 0 and epoch < self.wait:\n",
        "            return\n",
        "        if self.interval >= 0 and epoch % self.interval == 0:\n",
        "            rend = self.env.render(\"rgb_array\")\n",
        "            if self.frame is not None:\n",
        "                self.frame.append(self.env.render(\"rgb_array\"))\n",
        "        \n",
        "    def episode(self, epoch):\n",
        "        assert self.step_set\n",
        "        t=time.time()\n",
        "        buffer = []\n",
        "        self.obs = self.env.reset()\n",
        "        if self.cnn:\n",
        "            self.obs = self.actor.convert_input(self.env.render(\"rgb_array\"))\n",
        "        else:\n",
        "            self.render(epoch)\n",
        "\n",
        "        total_rew = 0\n",
        "        total_rew_scaled = 0\n",
        "        count = 0\n",
        "        while True:\n",
        "            with torch.no_grad():\n",
        "                out = self.actor(torch.FloatTensor([self.obs]).to(self.device))\n",
        "                act_v = out[0] if type(out) is tuple else out\n",
        "                act_v = act_v.cpu().squeeze(0).numpy()\n",
        "                if self.noise is not None:\n",
        "                    noise_v = act_v + self.noise.get_noise()\n",
        "                else:\n",
        "                    noise_v = act_v\n",
        "                if self.env.action_space.shape:\n",
        "                    noise_v = noise_v.clip(self.env.action_space.low, self.env.action_space.high)\n",
        "                act = self.actor.convert_to_action(noise_v)\n",
        "\n",
        "            next_obs, rew, done, etc = self.env.step(act)\n",
        "            obs = self.obs\n",
        "            if self.cnn:\n",
        "                next_obs = self.actor.convert_input(self.env.render(\"rgb_array\"))\n",
        "            else:\n",
        "                self.render(epoch)\n",
        "            self.obs = next_obs\n",
        "            count += 1\n",
        "\n",
        "            total_rew_scaled += rew\n",
        "            rew += self.bias\n",
        "            rew /= self.scale_factor\n",
        "            total_rew += rew\n",
        "\n",
        "            buffer.append(StepInfo(obs, act_v, noise_v, act, next_obs, rew, done, etc, -1))\n",
        "            if done:\n",
        "                break\n",
        "                \n",
        "            if len(buffer) < self.n_step:\n",
        "                continue\n",
        "                \n",
        "            yield self.unroll_step(buffer)\n",
        "            buffer.pop(0)\n",
        "            \n",
        "        while len(buffer):\n",
        "            yield self.unroll_step(buffer)\n",
        "            buffer.pop(0)\n",
        "        print(\"ep#%4d]\"%epoch, \"elapsed : %.2f, count : %4d, scaled_rew : %03.5f, total_rew : %03.5f\"%(time.time()-t, count, total_rew, total_rew_scaled))\n",
        "        return\n",
        "\n",
        "    def unroll_step(self, buffer):\n",
        "        assert len(buffer)\n",
        "        \n",
        "        rews = list(map(lambda b:b.rew, buffer))\n",
        "        rews.reverse()\n",
        "        rew_sum = 0\n",
        "\n",
        "        for r in rews:\n",
        "            rew_sum*=self.gamma\n",
        "            rew_sum+=r\n",
        "            \n",
        "        done = buffer[-1].done if len(buffer) == self.n_step else True\n",
        "        return StepInfo(buffer[0].obs, buffer[0].act_v, buffer[0].noise_v, buffer[0].act, buffer[-1].last_obs, rew_sum, done, buffer[0].etc, len(buffer))\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class NoiseMaker():\n",
        "    def __init__(self, action_size, n_type = None, param = None, decay = True):\n",
        "        self.action_size = action_size\n",
        "        self.state = np.zeros(action_size, dtype=np.float32)\n",
        "        self.count = 0\n",
        "        self.decay = decay\n",
        "        if n_type is None:\n",
        "            n_type = \"normal\"\n",
        "        self.type = n_type\n",
        "        \n",
        "        if param is None:\n",
        "            self.param = {\n",
        "                \"start\": 0.9,\n",
        "                \"end\":0.02,\n",
        "                \"decay\": 2000\n",
        "            }\n",
        "            if n_type ==\"ou\":\n",
        "                self.param[\"ou_mu\"] = 0.0\n",
        "                self.param[\"ou_th\"] = 0.15\n",
        "                self.param[\"ou_sig\"] = 0.2\n",
        "        else:\n",
        "            self.param = param\n",
        "            \n",
        "    def get_noise(self):\n",
        "        eps = self.param[\"end\"] + (self.param[\"start\"] - self.param[\"end\"]) * math.exp(-1*self.count/ self.param[\"decay\"])\n",
        "        \n",
        "        noise = np.random.normal(size=self.action_size)\n",
        "        if self.type == \"ou\":\n",
        "            self.state += self.param[\"ou_th\"] * (self.param[\"ou_mu\"] - self.state) + self.param[\"ou_sig\"] * noise\n",
        "            noise = self.state\n",
        "        if not self.decay:\n",
        "            eps = 1\n",
        "        self.count += 1\n",
        "            \n",
        "        return noise * eps\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class Replay:\n",
        "    def __init__(self, init, size, prio = False, alph = 0.6, beta = 0.4):\n",
        "        self.memory = collections.deque(maxlen = size)\n",
        "        self.init = init\n",
        "        self.size = size\n",
        "        self.priorities = collections.deque(maxlen = size)\n",
        "        self.prio = prio\n",
        "        self.alph = alph if prio else 0\n",
        "        self.beta = beta if prio else 0\n",
        "        self.count = 0\n",
        "        self.prepared = False\n",
        "        \n",
        "    def push(self, data):\n",
        "        self.memory.append(data)\n",
        "        self.count += 1\n",
        "        if self.prio:\n",
        "            max_prio = np.array(self.priorities).max() if len(self.priorities) else 1.\n",
        "            self.priorities.append(max_prio)\n",
        "        \n",
        "    def is_ready(self):\n",
        "        ret = len(self) >= self.init\n",
        "        if ret and not self.prepared:\n",
        "            self.prepared = True\n",
        "            print(\"replay memory is ready!\")\n",
        "        return ret\n",
        "        \n",
        "    def sample(self, size):\n",
        "        if self.prio:\n",
        "            probs = np.array(self.priorities, dtype=np.float32)\n",
        "            min_prio = np.array(self.priorities).min()\n",
        "            if min_prio < 1:\n",
        "                probs /= min_prio\n",
        "            probs = probs ** self.alph\n",
        "            probs /= probs.sum()\n",
        "        else:\n",
        "            probs = np.ones(len(self),) / len(self)\n",
        "        \n",
        "        indices = np.random.choice(len(self), size, p=probs)\n",
        "        sample = [self.memory[idx] for idx in indices]\n",
        "        \n",
        "        beta = 1. + (self.beta - 1.) * math.exp(-1 * self.count / self.size)\n",
        "        weights = (len(self) * probs[indices]) ** (-beta)\n",
        "        weights /= weights.sum()\n",
        "        \n",
        "        return sample, indices, weights\n",
        "        \n",
        "    def update_priorities(self, indices, prios):\n",
        "        if not self.prio:\n",
        "            return\n",
        "        prios += 1e-8\n",
        "        for idx, prio in zip(indices,prios):\n",
        "            self.priorities[idx] = prio\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "    \n",
        "import torch.nn as nn\n",
        "import copy\n",
        "\n",
        "class targetNet(nn.Module):\n",
        "    def __init__(self, off_net):\n",
        "        super(targetNet, self).__init__()\n",
        "        self.net = copy.deepcopy(off_net)\n",
        "        self.off_net = off_net\n",
        "        \n",
        "    def alpha_update(self, alpha = 0.05):\n",
        "        for off, tgt in zip(self.off_net.parameters(), self.net.parameters()):\n",
        "            tgt.data.copy_(off.data*alpha + tgt.data*(1-alpha))\n",
        "    \n",
        "    def copy_off_net(self):\n",
        "        self.net.load_state_dict(self.off_net.state_dict())\n",
        "    \n",
        "    def forward(self, *x):\n",
        "        return self.net(*x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzJ6JWB48EpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo6FSJY78Epu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, act_n, shape, hidden = 512):\n",
        "        super(Actor, self).__init__()\n",
        "        cnn_out_channel = 64\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, cnn_out_channel, 4, 2, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        w = self.get_conv_out_size(shape[1])\n",
        "        h = self.get_conv_out_size(shape[2])\n",
        "        self.cnn_out = w*h*cnn_out_channel\n",
        "        \n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(self.cnn_out, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, int(hidden/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(hidden/2), act_n),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return super(Actor,self).to(device)\n",
        "        \n",
        "    def convert_input(self, x):\n",
        "        return x[165:330].transpose(2,0,1)/255\n",
        "        \n",
        "    def convert_to_action(self, act_v):\n",
        "        return act_v.argmax()\n",
        "        \n",
        "    def get_conv_out_size(self, value):\n",
        "        return int(int(int(value/2)/2)/2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        cnn_out = self.cnn(x).view(-1,self.cnn_out)\n",
        "        return self.actor(cnn_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYBGzFK1a2BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, act_n, shape, hidden = 512):\n",
        "        super(Critic, self).__init__()\n",
        "        cnn_out_channel = 64\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, cnn_out_channel, 4, 2, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        w = self.get_conv_out_size(shape[1])\n",
        "        h = self.get_conv_out_size(shape[2])\n",
        "        self.cnn_out = w*h*cnn_out_channel\n",
        "        \n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(self.cnn_out, hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.critic_out = nn.Sequential(\n",
        "            nn.Linear(hidden + act_n, int(hidden/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(hidden/2), 1)\n",
        "        )\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return super(Critic,self).to(device)\n",
        "        \n",
        "    def get_conv_out_size(self, value):\n",
        "        return int(int(int(value/2)/2)/2)\n",
        "    \n",
        "    def forward(self, x, act_v=None):\n",
        "        cnn_out = self.cnn(x).view(-1,self.cnn_out)\n",
        "        return self.critic_out(torch.cat([self.critic(cnn_out), act_v],dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJhr-PUe8Ep3",
        "colab_type": "code",
        "outputId": "1d1a6a6c-2e1e-4dd0-ad6a-81d0b3639678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")\n",
        "act_n = env.action_space.n\n",
        "obs_n = env.observation_space.shape[0]\n",
        "\n",
        "env.reset()\n",
        "r = (env.render(\"rgb_array\")[165:330].transpose(2,0,1))\n",
        "env.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeC7sd9T8EqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h46folze8Eqo",
        "colab_type": "code",
        "outputId": "af336ecf-c373-4623-efdd-ca9ae729a903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "plt.imshow(r.transpose(1,2,0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faa93b82a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAB/CAYAAAAU5IInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2x3rLPw8ErE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 0.001\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "actor= Actor(act_n, r.shape).to(device)\n",
        "actor_tgt = targetNet(actor)\n",
        "actor_opt = optim.Adam(actor.parameters(), LR)\n",
        "critic= Critic(act_n, r.shape).to(device)\n",
        "critic_tgt = targetNet(critic)\n",
        "critic_opt = optim.Adam(critic.parameters(), LR)\n",
        "\n",
        "ST_SIZE = 10000\n",
        "ST_INIT = 2000\n",
        "ST_DECAY = 2000\n",
        "ST_BATCH = 64\n",
        "storage = Replay(ST_INIT, ST_SIZE, True)\n",
        "\n",
        "GAMMA = 0.99\n",
        "\n",
        "noise = NoiseMaker(act_n, \"normal\", decay = True)\n",
        "agent = Agent(env, actor, noise, 400, device=device)\n",
        "agent.prepare(3, GAMMA, True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWvnbpQ-8ErQ",
        "colab_type": "code",
        "outputId": "3fb3b6cd-54c6-4801-ac54-76f4f9df920a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCH = 1000\n",
        "for epoch in range(EPOCH):\n",
        "    for step in agent.episode(epoch):\n",
        "        storage.push(step)\n",
        "        if not storage.is_ready():\n",
        "            continue\n",
        "        \n",
        "        sample, indices, weights = storage.sample(ST_BATCH)\n",
        "        weights_ = torch.FloatTensor(weights).unsqueeze(1).to(device)\n",
        "        obs, act_v, noise_v, act, next_obs, rew, done, etc, unroll_n = list(zip(*sample))\n",
        "        \n",
        "        obs_ = torch.FloatTensor(obs).to(device)\n",
        "        act_v_ = torch.FloatTensor(act_v).to(device)\n",
        "        noise_v_ = torch.FloatTensor(noise_v).to(device)\n",
        "        act_ = torch.LongTensor(act).unsqueeze(1).to(device)\n",
        "        next_obs_ = torch.FloatTensor(next_obs).to(device)\n",
        "        rew_ = torch.FloatTensor(rew).unsqueeze(1).to(device)\n",
        "        done_ = torch.BoolTensor(done).to(device)\n",
        "        unroll_n_ = torch.FloatTensor(unroll_n).unsqueeze(1).to(device)\n",
        "\n",
        "        #critic\n",
        "        critic_opt.zero_grad()\n",
        "        q_pred = critic(obs_, noise_v_)\n",
        "        \n",
        "        q_next = critic_tgt(next_obs_, actor_tgt(next_obs_))\n",
        "        q_next[done_] = 0.\n",
        "        q_target = rew_ + (GAMMA ** unroll_n_) * q_next.detach()\n",
        "        \n",
        "        q_diff = (q_pred - q_target) ** 2\n",
        "        critic_loss = (weights_ * q_diff).sum()\n",
        "        critic_loss.backward()\n",
        "        critic_opt.step()\n",
        "        \n",
        "        storage.update_priorities(indices, q_diff.detach().cpu().numpy())\n",
        "        \n",
        "        #actor\n",
        "        actor_opt.zero_grad()\n",
        "        st_decay = torch.exp_(-torch.FloatTensor(len(storage)-indices)/ST_DECAY).unsqueeze(1).to(device)\n",
        "        act_avg = actor(obs_) * (1-st_decay) + act_v_ * st_decay\n",
        "\n",
        "        q_v = -critic(obs_, act_avg)\n",
        "\n",
        "        actor_loss = q_v.mean()\n",
        "        actor_loss.backward()\n",
        "        actor_opt.step()\n",
        "        \n",
        "        #target_update\n",
        "        actor_tgt.alpha_update()\n",
        "        critic_tgt.alpha_update()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ep#   0] elapsed : 0.54, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#   1] elapsed : 1.22, count :   36, scaled_rew : 36.00000, total_rew : 36.00000\n",
            "ep#   2] elapsed : 0.48, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#   3] elapsed : 0.54, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#   4] elapsed : 1.38, count :   41, scaled_rew : 41.00000, total_rew : 41.00000\n",
            "ep#   5] elapsed : 0.99, count :   28, scaled_rew : 28.00000, total_rew : 28.00000\n",
            "ep#   6] elapsed : 0.42, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#   7] elapsed : 0.52, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#   8] elapsed : 0.50, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#   9] elapsed : 0.48, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  10] elapsed : 0.49, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  11] elapsed : 0.92, count :   27, scaled_rew : 27.00000, total_rew : 27.00000\n",
            "ep#  12] elapsed : 1.28, count :   38, scaled_rew : 38.00000, total_rew : 38.00000\n",
            "ep#  13] elapsed : 0.37, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  14] elapsed : 0.43, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  15] elapsed : 0.63, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  16] elapsed : 0.45, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  17] elapsed : 0.88, count :   26, scaled_rew : 26.00000, total_rew : 26.00000\n",
            "ep#  18] elapsed : 0.38, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  19] elapsed : 2.11, count :   62, scaled_rew : 62.00000, total_rew : 62.00000\n",
            "ep#  20] elapsed : 0.73, count :   21, scaled_rew : 21.00000, total_rew : 21.00000\n",
            "ep#  21] elapsed : 1.44, count :   42, scaled_rew : 42.00000, total_rew : 42.00000\n",
            "ep#  22] elapsed : 0.81, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  23] elapsed : 1.59, count :   46, scaled_rew : 46.00000, total_rew : 46.00000\n",
            "ep#  24] elapsed : 0.98, count :   29, scaled_rew : 29.00000, total_rew : 29.00000\n",
            "ep#  25] elapsed : 0.52, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  26] elapsed : 1.19, count :   34, scaled_rew : 34.00000, total_rew : 34.00000\n",
            "ep#  27] elapsed : 0.34, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  28] elapsed : 0.45, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  29] elapsed : 0.46, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  30] elapsed : 0.82, count :   24, scaled_rew : 24.00000, total_rew : 24.00000\n",
            "ep#  31] elapsed : 0.41, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  32] elapsed : 0.85, count :   25, scaled_rew : 25.00000, total_rew : 25.00000\n",
            "ep#  33] elapsed : 0.44, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  34] elapsed : 1.55, count :   46, scaled_rew : 46.00000, total_rew : 46.00000\n",
            "ep#  35] elapsed : 0.27, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep#  36] elapsed : 3.90, count :  116, scaled_rew : 116.00000, total_rew : 116.00000\n",
            "ep#  37] elapsed : 0.87, count :   26, scaled_rew : 26.00000, total_rew : 26.00000\n",
            "ep#  38] elapsed : 0.62, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  39] elapsed : 1.09, count :   30, scaled_rew : 30.00000, total_rew : 30.00000\n",
            "ep#  40] elapsed : 0.65, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  41] elapsed : 0.51, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  42] elapsed : 0.89, count :   26, scaled_rew : 26.00000, total_rew : 26.00000\n",
            "ep#  43] elapsed : 1.09, count :   32, scaled_rew : 32.00000, total_rew : 32.00000\n",
            "ep#  44] elapsed : 0.41, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  45] elapsed : 0.59, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  46] elapsed : 0.83, count :   24, scaled_rew : 24.00000, total_rew : 24.00000\n",
            "ep#  47] elapsed : 1.20, count :   35, scaled_rew : 35.00000, total_rew : 35.00000\n",
            "ep#  48] elapsed : 0.32, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  49] elapsed : 0.35, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  50] elapsed : 0.40, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  51] elapsed : 0.76, count :   22, scaled_rew : 22.00000, total_rew : 22.00000\n",
            "ep#  52] elapsed : 0.93, count :   27, scaled_rew : 27.00000, total_rew : 27.00000\n",
            "ep#  53] elapsed : 0.78, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  54] elapsed : 0.52, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  55] elapsed : 1.87, count :   53, scaled_rew : 53.00000, total_rew : 53.00000\n",
            "ep#  56] elapsed : 0.65, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  57] elapsed : 0.56, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  58] elapsed : 0.47, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  59] elapsed : 0.91, count :   27, scaled_rew : 27.00000, total_rew : 27.00000\n",
            "ep#  60] elapsed : 0.48, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  61] elapsed : 0.95, count :   28, scaled_rew : 28.00000, total_rew : 28.00000\n",
            "ep#  62] elapsed : 0.62, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  63] elapsed : 1.43, count :   42, scaled_rew : 42.00000, total_rew : 42.00000\n",
            "ep#  64] elapsed : 0.50, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  65] elapsed : 0.54, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  66] elapsed : 0.42, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  67] elapsed : 1.01, count :   30, scaled_rew : 30.00000, total_rew : 30.00000\n",
            "ep#  68] elapsed : 0.78, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  69] elapsed : 0.58, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  70] elapsed : 1.58, count :   43, scaled_rew : 43.00000, total_rew : 43.00000\n",
            "ep#  71] elapsed : 0.57, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  72] elapsed : 0.69, count :   20, scaled_rew : 20.00000, total_rew : 20.00000\n",
            "ep#  73] elapsed : 0.48, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  74] elapsed : 0.69, count :   20, scaled_rew : 20.00000, total_rew : 20.00000\n",
            "ep#  75] elapsed : 0.44, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  76] elapsed : 0.62, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  77] elapsed : 0.38, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  78] elapsed : 0.62, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  79] elapsed : 0.45, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  80] elapsed : 1.17, count :   34, scaled_rew : 34.00000, total_rew : 34.00000\n",
            "ep#  81] elapsed : 0.57, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  82] elapsed : 0.59, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  83] elapsed : 1.57, count :   46, scaled_rew : 46.00000, total_rew : 46.00000\n",
            "ep#  84] elapsed : 0.64, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  85] elapsed : 0.97, count :   28, scaled_rew : 28.00000, total_rew : 28.00000\n",
            "replay memory is ready!\n",
            "ep#  86] elapsed : 17.51, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  87] elapsed : 49.89, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  88] elapsed : 117.26, count :   28, scaled_rew : 28.00000, total_rew : 28.00000\n",
            "ep#  89] elapsed : 63.32, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  90] elapsed : 46.99, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  91] elapsed : 59.94, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  92] elapsed : 77.22, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  93] elapsed : 102.05, count :   24, scaled_rew : 24.00000, total_rew : 24.00000\n",
            "ep#  94] elapsed : 106.12, count :   25, scaled_rew : 25.00000, total_rew : 25.00000\n",
            "ep#  95] elapsed : 151.83, count :   36, scaled_rew : 36.00000, total_rew : 36.00000\n",
            "ep#  96] elapsed : 95.51, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  97] elapsed : 65.49, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  98] elapsed : 164.04, count :   40, scaled_rew : 40.00000, total_rew : 40.00000\n",
            "ep#  99] elapsed : 232.33, count :   56, scaled_rew : 56.00000, total_rew : 56.00000\n",
            "ep# 100] elapsed : 98.08, count :   24, scaled_rew : 24.00000, total_rew : 24.00000\n",
            "ep# 101] elapsed : 84.97, count :   21, scaled_rew : 21.00000, total_rew : 21.00000\n",
            "ep# 102] elapsed : 76.71, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep# 103] elapsed : 56.46, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep# 104] elapsed : 51.97, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep# 105] elapsed : 71.43, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-568067dda4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mact_v_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnoise_v_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62UgwI3dI2eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        critic_opt.zero_grad()\n",
        "        actor_opt.zero_grad()\n",
        "        st_decay = torch.exp_(-torch.FloatTensor(len(storage)-indices)/ST_DECAY).unsqueeze(1).to(device)\n",
        "        act_avg = actor(obs_) * (1-st_decay) + act_v_ * st_decay\n",
        "\n",
        "        q_v = -critic(obs_, actor(obs_))\n",
        "\n",
        "        actor_loss = q_v.mean()\n",
        "        actor_loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}