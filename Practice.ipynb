{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Practice.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwwaS--8KTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "1ec5a863-0f45-44a0-bdab-9076f0af5bac"
      },
      "source": [
        "get_ipython().system('pip install gym pyvirtualdisplay > /dev/null 2>&1')\n",
        "get_ipython().system('apt-get update ')\n",
        "get_ipython().system('apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1')\n",
        "get_ipython().system('apt-get install x11-utils')\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "v_display = Display(visible=0, size=(1400,900),)\n",
        "v_display.start()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connectin\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpad.net\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Conne\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                                               \r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers]\r                                                                        \rHit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers]\r                                                                        \rIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                                        \r0% [1 InRelease gpgv 242 kB] [Waiting for headers]\r                                                  \rHit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to ppa.launchpad\r                                                                               \rHit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r                                                                               \r0% [1 InRelease gpgv 242 kB] [Connecting to ppa.launchpad.net (91.189.95.83)]\r                                                                             \rHit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1007'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1007'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUTrycae8Eo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import namedtuple\n",
        "\n",
        "version = \"1.0.0\"\n",
        "\n",
        "StepInfo = namedtuple(\"StepInfo\", (\"obs\", \"act_v\", \"noise_v\", \"act\", \"last_obs\", \"rew\", \"done\", \"etc\", \"n\"))\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, env, actor, noise = None, max_step = None, device=None):\n",
        "        self.env = env\n",
        "        if max_step is not None:\n",
        "            self.env._max_episode_steps = max_step           \n",
        "        self.actor = actor\n",
        "        self.noise = noise\n",
        "        self.device = device\n",
        "        \n",
        "        self.wait = -1\n",
        "        self.interval = -1\n",
        "        self.frame = None\n",
        "        \n",
        "        self.step_set = False\n",
        "        self.n_step = 1\n",
        "        self.gamma = 0.99\n",
        "        self.scale_factor = 1\n",
        "        self.bias=0\n",
        "        \n",
        "    def prepare(self, step_unroll, gamma, cnn=False, scale=1, bias=0):\n",
        "        self.step_set = True\n",
        "        self.n_step = step_unroll\n",
        "        self.gamma= gamma\n",
        "        self.scale_factor = scale\n",
        "        self.bias=bias\n",
        "        self.cnn = cnn\n",
        "        \n",
        "    def set_renderer(self, rend_wait=0, rend_interval=1, frame = None):\n",
        "        self.wait = rend_wait\n",
        "        self.interval = rend_interval\n",
        "        self.frame = frame\n",
        "        \n",
        "    def reset(self):\n",
        "        self.env.close()\n",
        "        self.env.reset()\n",
        "        \n",
        "    def render(self, epoch):\n",
        "        if self.wait >= 0 and epoch < self.wait:\n",
        "            return\n",
        "        if self.interval >= 0 and epoch % self.interval == 0:\n",
        "            rend = self.env.render(\"rgb_array\")\n",
        "            if self.frame is not None:\n",
        "                self.frame.append(self.env.render(\"rgb_array\"))\n",
        "        \n",
        "    def episode(self, epoch):\n",
        "        assert self.step_set\n",
        "        t=time.time()\n",
        "        buffer = []\n",
        "        self.obs = self.env.reset()\n",
        "        if self.cnn:\n",
        "            self.obs = self.actor.convert_input(self.env.render(\"rgb_array\"))\n",
        "        else:\n",
        "            self.render(epoch)\n",
        "\n",
        "        total_rew = 0\n",
        "        total_rew_scaled = 0\n",
        "        count = 0\n",
        "        while True:\n",
        "            with torch.no_grad():\n",
        "                out = self.actor(torch.FloatTensor([self.obs]).to(self.device))\n",
        "                act_v = out[0] if type(out) is tuple else out\n",
        "                act_v = act_v.cpu().squeeze(0).numpy()\n",
        "                if self.noise is not None:\n",
        "                    noise_v = act_v + self.noise.get_noise()\n",
        "                else:\n",
        "                    noise_v = act_v\n",
        "                if self.env.action_space.shape:\n",
        "                    noise_v = noise_v.clip(self.env.action_space.low, self.env.action_space.high)\n",
        "                act = self.actor.convert_to_action(noise_v)\n",
        "\n",
        "            next_obs, rew, done, etc = self.env.step(act)\n",
        "            obs = self.obs\n",
        "            next_obs = self.actor.convert_input(self.env.render(\"rgb_array\")) if self.cnn else next_obs\n",
        "            self.obs = next_obs\n",
        "            count += 1\n",
        "\n",
        "            total_rew_scaled += rew\n",
        "            rew += self.bias\n",
        "            rew /= self.scale_factor\n",
        "            total_rew += rew\n",
        "\n",
        "            self.render(epoch)\n",
        "\n",
        "            buffer.append(StepInfo(obs, act_v, noise_v, act, next_obs, rew, done, etc, -1))\n",
        "            if done:\n",
        "                break\n",
        "                \n",
        "            if len(buffer) < self.n_step:\n",
        "                continue\n",
        "                \n",
        "            yield self.unroll_step(buffer)\n",
        "            buffer.pop(0)\n",
        "            \n",
        "        while len(buffer):\n",
        "            yield self.unroll_step(buffer)\n",
        "            buffer.pop(0)\n",
        "        print(\"ep#%4d]\"%epoch, \"elapsed : %.2f, count : %4d, scaled_rew : %03.5f, total_rew : %03.5f\"%(time.time()-t, count, total_rew, total_rew_scaled))\n",
        "        return\n",
        "\n",
        "    def unroll_step(self, buffer):\n",
        "        assert len(buffer)\n",
        "        \n",
        "        rews = list(map(lambda b:b.rew, buffer))\n",
        "        rews.reverse()\n",
        "        rew_sum = 0\n",
        "\n",
        "        for r in rews:\n",
        "            rew_sum*=self.gamma\n",
        "            rew_sum+=r\n",
        "            \n",
        "        done = buffer[-1].done if len(buffer) == self.n_step else True\n",
        "        return StepInfo(buffer[0].obs, buffer[0].act_v, buffer[0].noise_v, buffer[0].act, buffer[-1].last_obs, rew_sum, done, buffer[0].etc, len(buffer))\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class NoiseMaker():\n",
        "    def __init__(self, action_size, n_type = None, param = None, decay = True):\n",
        "        self.action_size = action_size\n",
        "        self.state = np.zeros(action_size, dtype=np.float32)\n",
        "        self.count = 0\n",
        "        self.decay = decay\n",
        "        if n_type is None:\n",
        "            n_type = \"normal\"\n",
        "        self.type = n_type\n",
        "        \n",
        "        if param is None:\n",
        "            self.param = {\n",
        "                \"start\": 0.9,\n",
        "                \"end\":0.02,\n",
        "                \"decay\": 2000\n",
        "            }\n",
        "            if n_type ==\"ou\":\n",
        "                self.param[\"ou_mu\"] = 0.0\n",
        "                self.param[\"ou_th\"] = 0.15\n",
        "                self.param[\"ou_sig\"] = 0.2\n",
        "        else:\n",
        "            self.param = param\n",
        "            \n",
        "    def get_noise(self):\n",
        "        eps = self.param[\"end\"] + (self.param[\"start\"] - self.param[\"end\"]) * math.exp(-1*self.count/ self.param[\"decay\"])\n",
        "        \n",
        "        noise = np.random.normal(size=self.action_size)\n",
        "        if self.type == \"ou\":\n",
        "            self.state += self.param[\"ou_th\"] * (self.param[\"ou_mu\"] - self.state) + self.param[\"ou_sig\"] * noise\n",
        "            noise = self.state\n",
        "        if not self.decay:\n",
        "            eps = 1\n",
        "        self.count += 1\n",
        "            \n",
        "        return noise * eps\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class Replay:\n",
        "    def __init__(self, init, size, prio = False, alph = 0.6, beta = 0.4):\n",
        "        self.memory = collections.deque(maxlen = size)\n",
        "        self.init = init\n",
        "        self.size = size\n",
        "        self.priorities = collections.deque(maxlen = size)\n",
        "        self.prio = prio\n",
        "        self.alph = alph if prio else 0\n",
        "        self.beta = beta if prio else 0\n",
        "        self.count = 0\n",
        "        \n",
        "    def push(self, data):\n",
        "        self.memory.append(data)\n",
        "        self.count += 1\n",
        "        if self.prio:\n",
        "            max_prio = np.array(self.priorities).max() if len(self.priorities) else 1.\n",
        "            self.priorities.append(max_prio)\n",
        "        \n",
        "    def is_ready(self):\n",
        "        return len(self) >= self.init\n",
        "        \n",
        "    def sample(self, size):\n",
        "        if self.prio:\n",
        "            probs = np.array(self.priorities, dtype=np.float32)\n",
        "            min_prio = np.array(self.priorities).min()\n",
        "            if min_prio < 1:\n",
        "                probs /= min_prio\n",
        "            probs = probs ** self.alph\n",
        "            probs /= probs.sum()\n",
        "        else:\n",
        "            probs = np.ones(len(self),) / len(self)\n",
        "        \n",
        "        indices = np.random.choice(len(self), size, p=probs)\n",
        "        sample = [self.memory[idx] for idx in indices]\n",
        "        \n",
        "        beta = 1. + (self.beta - 1.) * math.exp(-1 * self.count / self.size)\n",
        "        weights = (len(self) * probs[indices]) ** (-beta)\n",
        "        weights /= weights.sum()\n",
        "        \n",
        "        return sample, indices, weights\n",
        "        \n",
        "    def update_priorities(self, indices, prios):\n",
        "        if not self.prio:\n",
        "            return\n",
        "        prios += 1e-8\n",
        "        for idx, prio in zip(indices,prios):\n",
        "            self.priorities[idx] = prio\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "    \n",
        "import torch.nn as nn\n",
        "import copy\n",
        "\n",
        "class targetNet(nn.Module):\n",
        "    def __init__(self, off_net):\n",
        "        super(targetNet, self).__init__()\n",
        "        self.net = copy.deepcopy(off_net)\n",
        "        self.off_net = off_net\n",
        "        \n",
        "    def alpha_update(self, alpha = 0.05):\n",
        "        for off, tgt in zip(self.off_net.parameters(), self.net.parameters()):\n",
        "            tgt.data.copy_(off.data*alpha + tgt.data*(1-alpha))\n",
        "    \n",
        "    def copy_off_net(self):\n",
        "        self.net.load_state_dict(self.off_net.state_dict())\n",
        "    \n",
        "    def forward(self, *x):\n",
        "        return self.net(*x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzJ6JWB48EpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo6FSJY78Epu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, act_n, shape, hidden = 512):\n",
        "        super(Actor, self).__init__()\n",
        "        cnn_out_channel = 64\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, cnn_out_channel, 4, 2, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        w = self.get_conv_out_size(shape[1])\n",
        "        h = self.get_conv_out_size(shape[2])\n",
        "        self.cnn_out = w*h*cnn_out_channel\n",
        "        \n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(self.cnn_out, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, int(hidden/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(hidden/2), act_n),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return super(Actor,self).to(device)\n",
        "        \n",
        "    def convert_input(self, x):\n",
        "        return x[165:330].transpose(2,0,1)\n",
        "        \n",
        "    def convert_to_action(self, act_v):\n",
        "        return act_v.argmax()\n",
        "        \n",
        "    def get_conv_out_size(self, value):\n",
        "        return int(int(int(value/2)/2)/2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        cnn_out = self.cnn(x).view(-1,self.cnn_out)\n",
        "        return self.actor(cnn_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYBGzFK1a2BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, act_n, shape, hidden = 512):\n",
        "        super(Critic, self).__init__()\n",
        "        cnn_out_channel = 64\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, cnn_out_channel, 4, 2, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        w = self.get_conv_out_size(shape[1])\n",
        "        h = self.get_conv_out_size(shape[2])\n",
        "        self.cnn_out = w*h*cnn_out_channel\n",
        "        \n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(self.cnn_out, hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.critic_out = nn.Sequential(\n",
        "            nn.Linear(hidden + act_n, int(hidden/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(hidden/2), 1)\n",
        "        )\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return super(Critic,self).to(device)\n",
        "        \n",
        "    def convert_input(self, x):\n",
        "        return x[165:330].transpose(2,0,1)\n",
        "        \n",
        "    def convert_to_action(self, act_v):\n",
        "        return act_v.argmax()\n",
        "        \n",
        "    def get_conv_out_size(self, value):\n",
        "        return int(int(int(value/2)/2)/2)\n",
        "    \n",
        "    def forward(self, x, act_v=None):\n",
        "        cnn_out = self.cnn(x).view(-1,self.cnn_out)\n",
        "        return self.critic_out(torch.cat([self.critic(cnn_out), act_v],dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJhr-PUe8Ep3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f014b51e-80fc-430f-c1eb-1b47d082a0cc"
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")\n",
        "act_n = env.action_space.n\n",
        "obs_n = env.observation_space.shape[0]\n",
        "\n",
        "env.reset()\n",
        "r = (env.render(\"rgb_array\")[165:330].transpose(2,0,1))\n",
        "env.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeC7sd9T8EqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h46folze8Eqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "9e185571-6d9c-4f83-90c7-cbc799260edf"
      },
      "source": [
        "plt.imshow(r.transpose(1,2,0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2241942b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAB/CAYAAAAU5IInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAKI0lEQVR4nO3df6jd9X3H8edrOu2Wlan1NgSj07YB\ncbBmzcVZ5h9pS7tUymyhiDJoGIHrHxY6GIxIYXX/bX9s3QpbMWOig03r2MQgMpulhf611pvW2qhN\nve0iJkRv2lpXKHSLfe+P87nZId7k/jg599zz8fmAL+f7/Xy/95z3m5y87vd+zo9vqgpJUl9+adIF\nSJIuPsNdkjpkuEtShwx3SeqQ4S5JHTLcJalDYwv3JHuSHEuykGT/uB5HkvRmGcf73JNcAnwP+DBw\nAngauKuqnr/oDyZJepNxnbnfDCxU1Q+q6n+AR4Dbx/RYkqRzjCvcrwFeHto+0cYkSRvg0kk9cJI5\nYA5gy5Ytu2688cZJlSJJU+nIkSM/rKqZ5faNK9xPAtcObW9vY2dV1QHgAMDs7GzNz8+PqRRJ6lOS\nl863b1zTMk8DO5LckOQy4E7g4JgeS5J0jrGcuVfVmSSfBp4CLgEeqKrnxvFY0rgdOXA3ALvm7p9w\nJdLqjW3OvaqeBJ4c1/1LG20p5JcY9trM/ISqJHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkd\nMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1KGR\nrqGa5DjwU+AN4ExVzSa5CvgScD1wHLijql4brUxJ0lpcjDP3D1TVzqqabdv7gcNVtQM43LYlSRto\nHNMytwMPtfWHgI+P4TEkSRcwargX8OUkR5LMtbGtVXWqrb8CbB3xMSRJazTSnDtwa1WdTPJO4FCS\n7w7vrKpKUsv9YPtlMAdw3XXXjViGNB5HDty97Piuufs3uBJpbUY6c6+qk+12EXgMuBl4Nck2gHa7\neJ6fPVBVs1U1OzMzM0oZkqRzrDvck2xJ8valdeAjwFHgILC3HbYXeHzUIiVJazPKtMxW4LEkS/fz\nz1X170meBh5Nsg94Cbhj9DIlSWux7nCvqh8A711m/EfAh0YpSpI0Gj+hKkkdMtwlqUOGuyR1yHCX\npA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq\nkOEuSR0y3CWpQ4a7JHVoxXBP8kCSxSRHh8auSnIoyYvt9so2niRfSLKQ5Nkk7xtn8ZKk5a3mzP1B\nYM85Y/uBw1W1AzjctgE+CuxoyxzwxYtTpiRpLVYM96r6GvDjc4ZvBx5q6w8BHx8a/8ca+E/giiTb\nLlaxkqTVWe+c+9aqOtXWXwG2tvVrgJeHjjvRxiRJG2jkF1SrqoBa688lmUsyn2T+9OnTo5YhSRqy\n3nB/dWm6pd0utvGTwLVDx21vY29SVQeqaraqZmdmZtZZhiRpOesN94PA3ra+F3h8aPxT7V0ztwCv\nD03fSJI2yKUrHZDkYWA3cHWSE8DngD8HHk2yD3gJuKMd/iRwG7AA/Az4wzHULElawYrhXlV3nWfX\nh5Y5toB7Ri1KkjQaP6EqSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS46y0nyaqXcd6HNE4rvs9d\neqt74tTc2fWPbTswwUqk1fPMXbqA4WBfblvarAx3aY0MeE0Dw12SOmS4S2vkvLumgS+oShdw332z\nZ9fn73c6RtPDcJdWafZuz9g1PTL4lt4JF5FMvghJmj5Hqmp2uR2b4sx9165dzM/PT7oMvUVs9AeL\nNsMJlPp0oeeyL6hKUocMd0nqkOEuSR1aMdyTPJBkMcnRobH7kpxM8kxbbhvad2+ShSTHkvzeuAqX\nJJ3fas7cHwT2LDP++ara2ZYnAZLcBNwJ/Gb7mb9LcsnFKlaStDorhntVfQ348Srv73bgkar6eVX9\nF7AA3DxCfZKkdRhlzv3TSZ5t0zZXtrFrgJeHjjnRxiRJG2i94f5F4N3ATuAU8JdrvYMkc0nmk8yf\nPn16nWVIa1dVG7pIk7CucK+qV6vqjar6BfD3/P/Uy0ng2qFDt7ex5e7jQFXNVtXszMzMesqQJJ3H\nusI9ybahzU8AS++kOQjcmeTyJDcAO4BvjFaiJGmtVvz6gSQPA7uBq5OcAD4H7E6yEyjgOHA3QFU9\nl+RR4HngDHBPVb0xntIlSeezKb44bHZ2tvxuGUlamyTn/eIwP6EqSR0y3CWpQ4a7JHVoU8y5J/kp\ncGzSdYzR1cAPJ13EGNnfdOu5v557A/iNqlr2veSb4mIdwLHzvSjQgyTz9je97G969dzbSpyWkaQO\nGe6S1KHNEu69X1be/qab/U2vnnu7oE3xgqok6eLaLGfukqSLaOLhnmRPuyTfQpL9k65nPc5zKcKr\nkhxK8mK7vbKNJ8kXWr/PJnnf5CpfWZJrk3w1yfNJnkvymTbeS39vS/KNJN9u/f1ZG78hyddbH19K\nclkbv7xtL7T910+y/tVKckmSbyV5om1301+S40m+0y75Od/Gunh+jmKi4d4uwfe3wEeBm4C72qX6\nps2DvPlShPuBw1W1AzjctmHQ6462zDH4bvzN7Azwx1V1E3ALcE/7N+qlv58DH6yq9zK4PsGeJLcA\nf8HgUpLvAV4D9rXj9wGvtfHPt+OmwWeAF4a2e+vvA+2Sn0tve+zl+bl+G33hgnMuYvB+4Kmh7XuB\neydZ0wi9XA8cHdo+Bmxr69sYvJcf4H7gruWOm4YFeBz4cI/9Ab8KfBP4HQYffLm0jZ99ngJPAe9v\n65e24zLp2lfoazuDgPsg8ASQzvo7Dlx9zlh3z8+1LpOelun5snxbq+pUW38F2NrWp7bn9if6bwNf\np6P+2pTFM8AicAj4PvCTqjrTDhnu4Wx/bf/rwDs2tuI1+2vgT4BftO130Fd/BXw5yZEkc22sm+fn\nem2WT6h2raoqyVS/LSnJrwH/CvxRVf13krP7pr2/GlxzYGeSK4DHgBsnXNJFk+RjwGJVHUmye9L1\njMmtVXUyyTuBQ0m+O7xz2p+f6zXpM/dVX5ZvCr26dMWqdrvYxqeu5yS/zCDY/6mq/q0Nd9Pfkqr6\nCfBVBtMUVyRZOvkZ7uFsf23/rwM/2uBS1+J3gd9Pchx4hMHUzN/QT39U1cl2u8jgl/PNdPj8XKtJ\nh/vTwI72yv1lwJ0MLtXXg4PA3ra+l8Fc9dL4p9qr9rcArw/9+bjpZHCK/g/AC1X1V0O7eulvpp2x\nk+RXGLye8AKDkP9kO+zc/pb6/iTwlWqTt5tRVd1bVdur6noG/7++UlV/QCf9JdmS5O1L68BHGFz2\ns4vn50gmPekP3AZ8j8E852cnXc86e3gYOAX8L4M5vH0M5ikPAy8C/wFc1Y4Ng3cIfR/4DjA76fpX\n6O1WBnOazwLPtOW2jvr7LeBbrb+jwJ+28XcxuP7vAvAvwOVt/G1te6Htf9eke1hDr7uBJ3rqr/Xx\n7bY8t5QhvTw/R1n8hKokdWjS0zKSpDEw3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tD/\nAXPWma87u1huAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2x3rLPw8ErE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 0.01\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "actor= Actor(act_n, r.shape).to(device)\n",
        "actor_tgt = targetNet(actor)\n",
        "actor_opt = optim.Adam(actor.parameters(), LR)\n",
        "critic= Critic(act_n, r.shape).to(device)\n",
        "critic_tgt = targetNet(critic)\n",
        "critic_opt = optim.Adam(critic.parameters(), LR)\n",
        "\n",
        "GAMMA = 0.99\n",
        "\n",
        "noise = NoiseMaker(act_n, \"normal\", decay = True)\n",
        "noise.param[\"ou_sig\"] = 0.6\n",
        "agent = Agent(env, actor, noise, 500, device=device)\n",
        "agent.prepare(2, GAMMA, True)\n",
        "\n",
        "ST_SIZE = 10000\n",
        "ST_INIT = 2000\n",
        "ST_DECAY = 2000\n",
        "ST_BATCH = 64\n",
        "storage = Replay(ST_INIT, ST_SIZE, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWvnbpQ-8ErQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec5647e2-bc03-49cb-a434-bcf1751e29f3"
      },
      "source": [
        "EPOCH = 1000\n",
        "for epoch in range(EPOCH):\n",
        "    for step in agent.episode(epoch):\n",
        "        storage.push(step)\n",
        "        if not storage.is_ready():\n",
        "            continue\n",
        "        \n",
        "        sample, indices, weights = storage.sample(ST_BATCH)\n",
        "        weights_ = torch.FloatTensor(weights).unsqueeze(1).to(device)\n",
        "        obs, act_v, noise_v, act, next_obs, rew, done, etc, unroll_n = list(zip(*sample))\n",
        "        \n",
        "        obs_ = torch.FloatTensor(obs).to(device)\n",
        "        act_v_ = torch.FloatTensor(act_v).to(device)\n",
        "        noise_v_ = torch.FloatTensor(noise_v).to(device)\n",
        "        act_ = torch.LongTensor(act).unsqueeze(1).to(device)\n",
        "        next_obs_ = torch.FloatTensor(next_obs).to(device)\n",
        "        rew_ = torch.FloatTensor(rew).unsqueeze(1).to(device)\n",
        "        done_ = torch.BoolTensor(done).to(device)\n",
        "        unroll_n_ = torch.FloatTensor(unroll_n).unsqueeze(1).to(device)\n",
        "\n",
        "        #critic\n",
        "        critic_opt.zero_grad()\n",
        "        q_pred = critic(obs_, noise_v_)\n",
        "        \n",
        "        q_next = critic_tgt(next_obs_, actor_tgt(next_obs_))\n",
        "        q_next[done_] = 0.\n",
        "        q_target = rew_ + (GAMMA ** unroll_n_) * q_next.detach()\n",
        "        \n",
        "        q_loss = weights_ * (q_next - q_target) ** 2\n",
        "        q_loss.sum().backward()\n",
        "        critic_opt.step()\n",
        "        \n",
        "        storage.update_priorities(indices, q_loss.detach().cpu().numpy())\n",
        "        \n",
        "        #actor\n",
        "        actor_opt.zero_grad()\n",
        "        st_decay = torch.exp_(-torch.FloatTensor(len(storage)-indices)/ST_DECAY).unsqueeze(1).to(device)\n",
        "        act_avg = actor(obs_) * (1-st_decay) + act_v_ * st_decay\n",
        "\n",
        "        q_v = -critic(obs_, act_avg)\n",
        "\n",
        "        actor_loss = q_v.mean()\n",
        "        actor_loss.backward()\n",
        "        actor_opt.step()\n",
        "        \n",
        "        #target_update\n",
        "        actor_tgt.alpha_update()\n",
        "        critic_tgt.alpha_update()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ep#   0] elapsed : 0.63, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#   1] elapsed : 0.61, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#   2] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#   3] elapsed : 1.52, count :   35, scaled_rew : 35.00000, total_rew : 35.00000\n",
            "ep#   4] elapsed : 1.88, count :   43, scaled_rew : 43.00000, total_rew : 43.00000\n",
            "ep#   5] elapsed : 0.51, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#   6] elapsed : 0.70, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#   7] elapsed : 0.95, count :   22, scaled_rew : 22.00000, total_rew : 22.00000\n",
            "ep#   8] elapsed : 0.46, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#   9] elapsed : 0.71, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  10] elapsed : 0.58, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  11] elapsed : 1.62, count :   34, scaled_rew : 34.00000, total_rew : 34.00000\n",
            "ep#  12] elapsed : 1.24, count :   28, scaled_rew : 28.00000, total_rew : 28.00000\n",
            "ep#  13] elapsed : 0.53, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  14] elapsed : 0.91, count :   20, scaled_rew : 20.00000, total_rew : 20.00000\n",
            "ep#  15] elapsed : 1.78, count :   41, scaled_rew : 41.00000, total_rew : 41.00000\n",
            "ep#  16] elapsed : 0.64, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  17] elapsed : 0.48, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  18] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  19] elapsed : 0.82, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  20] elapsed : 1.47, count :   34, scaled_rew : 34.00000, total_rew : 34.00000\n",
            "ep#  21] elapsed : 0.61, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  22] elapsed : 0.49, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  23] elapsed : 1.02, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  24] elapsed : 0.58, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  25] elapsed : 0.42, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  26] elapsed : 0.84, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  27] elapsed : 1.09, count :   24, scaled_rew : 24.00000, total_rew : 24.00000\n",
            "ep#  28] elapsed : 0.66, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  29] elapsed : 0.70, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  30] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  31] elapsed : 0.99, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  32] elapsed : 1.00, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  33] elapsed : 0.80, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  34] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  35] elapsed : 1.00, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  36] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  37] elapsed : 0.83, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  38] elapsed : 0.51, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  39] elapsed : 1.62, count :   35, scaled_rew : 35.00000, total_rew : 35.00000\n",
            "ep#  40] elapsed : 0.61, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  41] elapsed : 0.54, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  42] elapsed : 0.83, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  43] elapsed : 1.42, count :   33, scaled_rew : 33.00000, total_rew : 33.00000\n",
            "ep#  44] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  45] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  46] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  47] elapsed : 0.81, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  48] elapsed : 0.57, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  49] elapsed : 0.61, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  50] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  51] elapsed : 0.44, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  52] elapsed : 0.65, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  53] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  54] elapsed : 0.74, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  55] elapsed : 0.58, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  56] elapsed : 1.03, count :   22, scaled_rew : 22.00000, total_rew : 22.00000\n",
            "ep#  57] elapsed : 1.04, count :   22, scaled_rew : 22.00000, total_rew : 22.00000\n",
            "ep#  58] elapsed : 0.35, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep#  59] elapsed : 0.49, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  60] elapsed : 1.08, count :   25, scaled_rew : 25.00000, total_rew : 25.00000\n",
            "ep#  61] elapsed : 0.48, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  62] elapsed : 0.87, count :   20, scaled_rew : 20.00000, total_rew : 20.00000\n",
            "ep#  63] elapsed : 0.63, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep#  64] elapsed : 0.72, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  65] elapsed : 1.16, count :   27, scaled_rew : 27.00000, total_rew : 27.00000\n",
            "ep#  66] elapsed : 1.07, count :   25, scaled_rew : 25.00000, total_rew : 25.00000\n",
            "ep#  67] elapsed : 0.48, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  68] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  69] elapsed : 0.75, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  70] elapsed : 1.37, count :   32, scaled_rew : 32.00000, total_rew : 32.00000\n",
            "ep#  71] elapsed : 0.57, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  72] elapsed : 0.72, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep#  73] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  74] elapsed : 0.57, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  75] elapsed : 0.51, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  76] elapsed : 0.77, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  77] elapsed : 0.51, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  78] elapsed : 0.75, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  79] elapsed : 0.35, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep#  80] elapsed : 0.48, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep#  81] elapsed : 1.08, count :   25, scaled_rew : 25.00000, total_rew : 25.00000\n",
            "ep#  82] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  83] elapsed : 0.75, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  84] elapsed : 0.78, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep#  85] elapsed : 0.60, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep#  86] elapsed : 0.57, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  87] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep#  88] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  89] elapsed : 0.92, count :   19, scaled_rew : 19.00000, total_rew : 19.00000\n",
            "ep#  90] elapsed : 0.83, count :   17, scaled_rew : 17.00000, total_rew : 17.00000\n",
            "ep#  91] elapsed : 0.51, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep#  92] elapsed : 1.31, count :   31, scaled_rew : 31.00000, total_rew : 31.00000\n",
            "ep#  93] elapsed : 1.00, count :   23, scaled_rew : 23.00000, total_rew : 23.00000\n",
            "ep#  94] elapsed : 0.40, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  95] elapsed : 0.58, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep#  96] elapsed : 0.36, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep#  97] elapsed : 1.11, count :   26, scaled_rew : 26.00000, total_rew : 26.00000\n",
            "ep#  98] elapsed : 0.39, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep#  99] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep# 100] elapsed : 0.47, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep# 101] elapsed : 0.65, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep# 102] elapsed : 1.17, count :   27, scaled_rew : 27.00000, total_rew : 27.00000\n",
            "ep# 103] elapsed : 0.59, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep# 104] elapsed : 0.78, count :   18, scaled_rew : 18.00000, total_rew : 18.00000\n",
            "ep# 105] elapsed : 0.67, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep# 106] elapsed : 0.74, count :   16, scaled_rew : 16.00000, total_rew : 16.00000\n",
            "ep# 107] elapsed : 0.52, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep# 108] elapsed : 0.60, count :   14, scaled_rew : 14.00000, total_rew : 14.00000\n",
            "ep# 109] elapsed : 0.38, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 110] elapsed : 0.51, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep# 111] elapsed : 0.46, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep# 112] elapsed : 0.55, count :   13, scaled_rew : 13.00000, total_rew : 13.00000\n",
            "ep# 113] elapsed : 0.55, count :   12, scaled_rew : 12.00000, total_rew : 12.00000\n",
            "ep# 114] elapsed : 1.16, count :   27, scaled_rew : 27.00000, total_rew : 27.00000\n",
            "ep# 115] elapsed : 0.43, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 116] elapsed : 0.45, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 117] elapsed : 0.51, count :   11, scaled_rew : 11.00000, total_rew : 11.00000\n",
            "ep# 118] elapsed : 0.67, count :   15, scaled_rew : 15.00000, total_rew : 15.00000\n",
            "ep# 119] elapsed : 0.37, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep# 120] elapsed : 1.00, count :   22, scaled_rew : 22.00000, total_rew : 22.00000\n",
            "ep# 121] elapsed : 11.20, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 122] elapsed : 52.22, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 123] elapsed : 59.05, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 124] elapsed : 52.07, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 125] elapsed : 57.86, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 126] elapsed : 52.02, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n",
            "ep# 127] elapsed : 56.45, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 128] elapsed : 55.31, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 129] elapsed : 44.08, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep# 130] elapsed : 43.74, count :    8, scaled_rew : 8.00000, total_rew : 8.00000\n",
            "ep# 131] elapsed : 55.32, count :   10, scaled_rew : 10.00000, total_rew : 10.00000\n",
            "ep# 132] elapsed : 49.86, count :    9, scaled_rew : 9.00000, total_rew : 9.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk0TuHuKghQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q_v"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}