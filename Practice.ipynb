{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, act_n, shape, hidden = 512):\n",
    "        super(Net, self).__init__()\n",
    "        cnn_out_channel = 64\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, cnn_out_channel, 4, 2, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        w = self.get_conv_out_size(shape[1])\n",
    "        h = self.get_conv_out_size(shape[2])\n",
    "        self.cnn_out = w*h*cnn_out_channel\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(self.cnn_out, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, int(hidden/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden/2), act_n),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(self.cnn_out, hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.critic_out = nn.Sequential(\n",
    "            nn.Linear(hidden + act_n, int(hidden/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden/2), 1)\n",
    "        )\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        return super(Net,self).to(device)\n",
    "        \n",
    "    def convert_input(self, x):\n",
    "        return x[165:330,200:400].transpose(2,0,1)\n",
    "        \n",
    "    def convert_to_action(self, act_v):\n",
    "        return act_v.argmax()\n",
    "        \n",
    "    def get_conv_out_size(self, value):\n",
    "        return int(int(int(value/2)/2)/2)\n",
    "    \n",
    "    def forward(self, x, act_v=None):\n",
    "        x = torch.FloatTensor(x).to(self.device)\n",
    "        cnn_out = self.cnn(x).view(-1,self.cnn_out)\n",
    "        if act_v is None:\n",
    "            return self.actor(cnn_out)\n",
    "        else:\n",
    "            return self.critic_out(torch.cat([self.critic(cnn_out), act_v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "act_n = env.action_space.n\n",
    "obs_n = env.observation_space.shape[0]\n",
    "\n",
    "env.reset()\n",
    "r = (env.render(\"rgb_array\")[165:330,200:400].transpose(2,0,1))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c43c6c33c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(r.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "net= Net(act_n, r.shape).to(device)\n",
    "net_tgt = targetNet(net)\n",
    "opt = optim.Adam(net.parameters(), LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "\n",
    "noise = NoiseMaker(act_n, \"normal\", decay = True)\n",
    "agent = Agent(env, net, noise, 500)\n",
    "agent.prepare(2, GAMMA, True)\n",
    "\n",
    "ST_SIZE = 10000\n",
    "ST_INIT = 5\n",
    "ST_DECAY = 1000\n",
    "ST_BATCH = 32\n",
    "storage = Replay(ST_INIT, ST_SIZE, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "EPOCH = 2\n",
    "for epoch in range(EPOCH):\n",
    "    for step in agent.episode(epoch):\n",
    "        storage.push(step)\n",
    "        if not storage.is_ready():\n",
    "            continue\n",
    "        \n",
    "        sample, indices, weights = storage.sample(ST_BATCH)\n",
    "        weights_ = torch.FloatTensor(weights).to(device)\n",
    "        obs, act_v, noise_v, act, next_obs, rew, done, etc, unroll_n = list(zip(*sample))\n",
    "        \n",
    "        obs_ = torch.FloatTensor(obs).to(device)\n",
    "        act_v_ = torch.FloatTensor(act_v).to(device)\n",
    "        noise_v_ = torch.FloatTensor(noise_v).to(device)\n",
    "        act_ = torch.LongTensor(act).unsqueeze(1).to(device)\n",
    "        next_obs_ = torch.FloatTensor(next_obs).to(device)\n",
    "        rew_ = torch.FloatTensor(rew).unsqueeze(1).to(device)\n",
    "        done_ = torch.BoolTensor(done).to(device)\n",
    "        unroll_n_ = torch.FloatTensor(unroll_n).unsqueeze(1).to(device)\n",
    "\n",
    "        #critic\n",
    "        opt.zero_grad()\n",
    "        q_pred = net(obs_, noise_v_)\n",
    "        \n",
    "        q_next = targetNet(next_obs_, targetNet(next_obs_))\n",
    "        q_next[done] = 0.\n",
    "        q_target = rew_ + (GAMMA ** unroll_n_) * q_next.detach()\n",
    "        \n",
    "        q_loss = weight_ * (q_next - q_target) ** 2\n",
    "        q_loss.mean().backward()\n",
    "        opt.step()\n",
    "        \n",
    "        storage.update_priorities(indices, q_loss.detach().cpu().numpy())\n",
    "        \n",
    "        #actor\n",
    "        st_decay = torch.exp_(-torch.FloatTensor(len(storage)-indices)/ST_DECAY).unsqueeze(1).to(device)\n",
    "        act_avg = net(obs_).detach() * (1-st_decay) + act_v_ * st_decay\n",
    "        q_v = -net(obs_, act_avg)\n",
    "\n",
    "        actor_loss = q_v.mean()\n",
    "        actor_loss.backward()\n",
    "        actor_optim.step()\n",
    "        \n",
    "        #target_update\n",
    "        targetNet.alpha_update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
